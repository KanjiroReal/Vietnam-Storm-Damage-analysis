{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0T0Cld7b4swH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u0SL97LT47qH"
      },
      "outputs": [],
      "source": [
        "# Đọc dữ liệu\n",
        "df = pd.read_csv('STORM_RAW_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "2MRPVC3q5Fl9",
        "outputId": "c6844f69-886c-4dd6-eeea-9a25260b3af7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>EventName</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>DisasterType</th>\n",
              "      <th>DisasterSubtype</th>\n",
              "      <th>MainLandfallLocation</th>\n",
              "      <th>Flood</th>\n",
              "      <th>Slide</th>\n",
              "      <th>OFDAResponse</th>\n",
              "      <th>Appeal</th>\n",
              "      <th>Declaration</th>\n",
              "      <th>LandfallMagnitude(kph)</th>\n",
              "      <th>LandfallPressure(mb)</th>\n",
              "      <th>TotalDeaths</th>\n",
              "      <th>NoInjured</th>\n",
              "      <th>TotalDamage(000US$)</th>\n",
              "      <th>TotalDamageAdjusted(000US$)</th>\n",
              "      <th>CPI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>STORM_NAN_1953</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1953</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>Mekong River Delta</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>985.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>89730.0</td>\n",
              "      <td>139143.00</td>\n",
              "      <td>9.156133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>STORM_VIOLET_1964</td>\n",
              "      <td>Violet</td>\n",
              "      <td>1964</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>North Central Coast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>985.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>94354.08</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>STORM_IRIS_1964</td>\n",
              "      <td>Iris</td>\n",
              "      <td>1964</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>South Central Coast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>5100.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>660478.55</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>STORM_JOAN_1964</td>\n",
              "      <td>Joan</td>\n",
              "      <td>1964</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>South Central Coast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>980.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>141531.12</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>STORM_KATE_1964</td>\n",
              "      <td>Kate</td>\n",
              "      <td>1964</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>Central Highlands</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>970.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>28306.22</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                 ID EventName  Year  Month DisasterType  \\\n",
              "0           0     STORM_NAN_1953       NaN  1953    9.0        Storm   \n",
              "1           1  STORM_VIOLET_1964   Violet   1964    9.0        Storm   \n",
              "2           2    STORM_IRIS_1964      Iris  1964   11.0        Storm   \n",
              "3           3    STORM_JOAN_1964      Joan  1964   11.0        Storm   \n",
              "4           4    STORM_KATE_1964      Kate  1964   11.0        Storm   \n",
              "\n",
              "    DisasterSubtype MainLandfallLocation  Flood  Slide  OFDAResponse  Appeal  \\\n",
              "0  Tropical cyclone   Mekong River Delta    0.0    0.0           0.0     0.0   \n",
              "1  Tropical cyclone  North Central Coast    NaN    NaN           0.0     0.0   \n",
              "2  Tropical cyclone  South Central Coast    NaN    NaN           0.0     0.0   \n",
              "3  Tropical cyclone  South Central Coast    NaN    NaN           0.0     0.0   \n",
              "4  Tropical cyclone    Central Highlands    NaN    NaN           0.0     0.0   \n",
              "\n",
              "   Declaration  LandfallMagnitude(kph)  LandfallPressure(mb)  TotalDeaths  \\\n",
              "0          0.0                    93.0                 985.0       1000.0   \n",
              "1          0.0                    93.0                 985.0        124.0   \n",
              "2          0.0                   150.0                 960.0       5100.0   \n",
              "3          0.0                   130.0                 980.0       2500.0   \n",
              "4          0.0                   130.0                 970.0          0.0   \n",
              "\n",
              "   NoInjured  TotalDamage(000US$)  TotalDamageAdjusted(000US$)        CPI  \n",
              "0      146.0              89730.0                    139143.00   9.156133  \n",
              "1      146.0              10000.0                     94354.08  10.598376  \n",
              "2      146.0              70000.0                    660478.55  10.598376  \n",
              "3      146.0              15000.0                    141531.12  10.598376  \n",
              "4      146.0               3000.0                     28306.22  10.598376  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "65EpfOIY8QCx"
      },
      "outputs": [],
      "source": [
        "# Xóa các cột không cần thiết\n",
        "df = df.drop(['OFDAResponse', 'Appeal', 'Declaration', 'CPI'], axis=1)\n",
        "\n",
        "# Xử lý giá trị NaN\n",
        "df['Flood'] = df['Flood'].fillna(0)\n",
        "df['Slide'] = df['Slide'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KhDUSxPDE6X",
        "outputId": "b2dd1b6f-18b9-440e-8b66-9da0ffa0fcff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Mekong River Delta' 'North Central Coast' 'South Central Coast'\n",
            " 'Central Highlands' 'SouthEast' 'Red River Delta' 'NorthEast' nan\n",
            " 'NorthWest']\n"
          ]
        }
      ],
      "source": [
        "unique_values = df['MainLandfallLocation'].unique()\n",
        "\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yFhYAaAqDXQG"
      },
      "outputs": [],
      "source": [
        "# Mapping cho MainLandfallLocation\n",
        "landfall_mapping = {\n",
        "    'NorthEast': 1,\n",
        "    'NorthWest': 2,\n",
        "    'Red River Delta': 3,\n",
        "    'North Central Coast': 4,\n",
        "    'South Central Coast': 5,\n",
        "    'Central Highlands': 6,\n",
        "    'SouthEast': 7,\n",
        "    'Mekong River Delta': 8\n",
        "}\n",
        "df['MainLandfallLocation'] = df['MainLandfallLocation'].map(landfall_mapping)\n",
        "\n",
        "# One-hot encoding cho các cột phân loại\n",
        "categorical_cols = ['DisasterType', 'DisasterSubtype']\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhhv3hKQLMaA",
        "outputId": "d064006e-482a-4e24-eefd-46f5a10e8e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame contains NaN values. Please check your data.\n"
          ]
        }
      ],
      "source": [
        "# Chuẩn hóa các cột số\n",
        "scaler = StandardScaler()\n",
        "df[['LandfallMagnitude(kph)', 'LandfallPressure(mb)']] = scaler.fit_transform(df[['LandfallMagnitude(kph)', 'LandfallPressure(mb)']])\n",
        "\n",
        "# Kiểm tra giá trị NaN\n",
        "if df.isnull().values.any():\n",
        "    print(\"DataFrame contains NaN values. Please check your data.\")\n",
        "\n",
        "# Tạo X và y\n",
        "predictors = ['LandfallMagnitude(kph)', 'LandfallPressure(mb)', 'Flood', 'Slide', 'Year', 'Month'] + \\\n",
        "             [col for col in df.columns if col.startswith('MainLandfallLocation_') or col.startswith('DisasterSubtype_')]\n",
        "\n",
        "X = df[predictors]\n",
        "y = df[['TotalDeaths', 'NoInjured', 'TotalDamageAdjusted(000US$)']]\n",
        "\n",
        "# Kiểm tra NaN trong y\n",
        "y = y.fillna(0)  # Hoặc thay thế bằng giá trị trung bình\n",
        "\n",
        "# Chuẩn hóa dữ liệu X\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "PYnRMQR3SUQY"
      },
      "outputs": [],
      "source": [
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lDpledFS15g"
      },
      "source": [
        "**thử với MLP nhưng bị nan**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rs4WoVfSVNf",
        "outputId": "277b2049-508f-4b87-d19f-b39bc5ee6f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: nan - val_loss: nan\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: nan - val_loss: nan\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: nan - val_loss: nan\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: nan - val_loss: nan\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo mô hình Sequential\n",
        "model = Sequential()\n",
        "\n",
        "# Thêm các hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Layer đầu ra (3 node cho 3 feature trong y)\n",
        "model.add(Dense(3))\n",
        "\n",
        "# Compile mô hình\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\anhmi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 16902643712.0000 - mae: 44236.6172 - val_loss: 28470239232.0000 - val_mae: 47764.3945\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 22583275520.0000 - mae: 51556.1172 - val_loss: 28470235136.0000 - val_mae: 47764.3750\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 16426182656.0000 - mae: 44006.8555 - val_loss: 28470231040.0000 - val_mae: 47764.3594\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21577543680.0000 - mae: 49263.0508 - val_loss: 28470231040.0000 - val_mae: 47764.3477\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18459719680.0000 - mae: 46809.3242 - val_loss: 28470222848.0000 - val_mae: 47764.3320\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 16573284352.0000 - mae: 42204.0156 - val_loss: 28470220800.0000 - val_mae: 47764.3125\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16201964544.0000 - mae: 44153.9922 - val_loss: 28470216704.0000 - val_mae: 47764.3008\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 18764345344.0000 - mae: 46131.7109 - val_loss: 28470216704.0000 - val_mae: 47764.2891\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21822269440.0000 - mae: 50355.5664 - val_loss: 28470206464.0000 - val_mae: 47764.2695\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17397391360.0000 - mae: 44523.1602 - val_loss: 28470206464.0000 - val_mae: 47764.2617\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14870018048.0000 - mae: 41929.3516 - val_loss: 28470202368.0000 - val_mae: 47764.2422\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 25470818304.0000 - mae: 52781.8984 - val_loss: 28470198272.0000 - val_mae: 47764.2344\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21670678528.0000 - mae: 49456.1406 - val_loss: 28470194176.0000 - val_mae: 47764.2148\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18283272192.0000 - mae: 45481.2422 - val_loss: 28470192128.0000 - val_mae: 47764.2031\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 19918766080.0000 - mae: 48904.8125 - val_loss: 28470181888.0000 - val_mae: 47764.1836\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20005109760.0000 - mae: 47023.3789 - val_loss: 28470181888.0000 - val_mae: 47764.1719\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18508056576.0000 - mae: 47305.3789 - val_loss: 28470177792.0000 - val_mae: 47764.1445\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19457894400.0000 - mae: 45499.1992 - val_loss: 28470169600.0000 - val_mae: 47764.1211\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 19159656448.0000 - mae: 45813.0352 - val_loss: 28470167552.0000 - val_mae: 47764.1016\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21878601728.0000 - mae: 47801.3672 - val_loss: 28470163456.0000 - val_mae: 47764.0781\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17737338880.0000 - mae: 45499.0664 - val_loss: 28470159360.0000 - val_mae: 47764.0625\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21518815232.0000 - mae: 47534.2734 - val_loss: 28470155264.0000 - val_mae: 47764.0391\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 19010232320.0000 - mae: 45160.2578 - val_loss: 28470149120.0000 - val_mae: 47764.0117\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21905811456.0000 - mae: 49487.7578 - val_loss: 28470145024.0000 - val_mae: 47763.9844\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17972271104.0000 - mae: 45747.8281 - val_loss: 28470138880.0000 - val_mae: 47763.9609\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 22364659712.0000 - mae: 50423.9375 - val_loss: 28470130688.0000 - val_mae: 47763.9297\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16553763840.0000 - mae: 42195.0195 - val_loss: 28470124544.0000 - val_mae: 47763.8945\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23996538880.0000 - mae: 51695.2227 - val_loss: 28470116352.0000 - val_mae: 47763.8594\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17212198912.0000 - mae: 46058.5117 - val_loss: 28470110208.0000 - val_mae: 47763.8281\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 19202674688.0000 - mae: 46543.4336 - val_loss: 28470099968.0000 - val_mae: 47763.7891\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 18621046784.0000 - mae: 44867.6406 - val_loss: 28470091776.0000 - val_mae: 47763.7422\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18703538176.0000 - mae: 47919.0508 - val_loss: 28470083584.0000 - val_mae: 47763.7031\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17026719744.0000 - mae: 44999.0078 - val_loss: 28470075392.0000 - val_mae: 47763.6484\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23748751360.0000 - mae: 53280.0312 - val_loss: 28470067200.0000 - val_mae: 47763.6016\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20587350016.0000 - mae: 46521.2031 - val_loss: 28470059008.0000 - val_mae: 47763.5625\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15465699328.0000 - mae: 41171.7383 - val_loss: 28470052864.0000 - val_mae: 47763.5312\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15630931968.0000 - mae: 42291.2812 - val_loss: 28470050816.0000 - val_mae: 47763.5000\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19334717440.0000 - mae: 45801.8594 - val_loss: 28470042624.0000 - val_mae: 47763.4609\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20541861888.0000 - mae: 46651.0273 - val_loss: 28470038528.0000 - val_mae: 47763.4258\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16002763776.0000 - mae: 43748.2578 - val_loss: 28470028288.0000 - val_mae: 47763.3867\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 23286521856.0000 - mae: 49210.6367 - val_loss: 28470022144.0000 - val_mae: 47763.3477\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 18787864576.0000 - mae: 45117.3438 - val_loss: 28470016000.0000 - val_mae: 47763.3125\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 20889837568.0000 - mae: 46763.2734 - val_loss: 28470011904.0000 - val_mae: 47763.2773\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 19791857664.0000 - mae: 47036.2305 - val_loss: 28470003712.0000 - val_mae: 47763.2227\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17639821312.0000 - mae: 45113.7422 - val_loss: 28469993472.0000 - val_mae: 47763.1758\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 20430585856.0000 - mae: 46481.0859 - val_loss: 28469983232.0000 - val_mae: 47763.1133\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18948667392.0000 - mae: 45727.5195 - val_loss: 28469972992.0000 - val_mae: 47763.0547\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17276024832.0000 - mae: 44215.8867 - val_loss: 28469964800.0000 - val_mae: 47763.0000\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17359353856.0000 - mae: 43983.8398 - val_loss: 28469954560.0000 - val_mae: 47762.9375\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17796855808.0000 - mae: 46474.8984 - val_loss: 28469946368.0000 - val_mae: 47762.8867\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20125110272.0000 - mae: 48270.7305 - val_loss: 28469944320.0000 - val_mae: 47762.8594\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21910779904.0000 - mae: 51310.6992 - val_loss: 28469940224.0000 - val_mae: 47762.8164\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21806950400.0000 - mae: 49259.2656 - val_loss: 28469936128.0000 - val_mae: 47762.7812\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20587669504.0000 - mae: 45657.6484 - val_loss: 28469929984.0000 - val_mae: 47762.7227\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16380655616.0000 - mae: 43402.1172 - val_loss: 28469917696.0000 - val_mae: 47762.6562\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18731984896.0000 - mae: 47028.4453 - val_loss: 28469905408.0000 - val_mae: 47762.5820\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16684236800.0000 - mae: 43749.1719 - val_loss: 28469886976.0000 - val_mae: 47762.4922\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 22449664000.0000 - mae: 49486.1719 - val_loss: 28469868544.0000 - val_mae: 47762.3984\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18125733888.0000 - mae: 47819.1914 - val_loss: 28469858304.0000 - val_mae: 47762.3164\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18007222272.0000 - mae: 48486.9805 - val_loss: 28469848064.0000 - val_mae: 47762.2461\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21494288384.0000 - mae: 46628.7617 - val_loss: 28469827584.0000 - val_mae: 47762.1406\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16132337664.0000 - mae: 44674.3086 - val_loss: 28469805056.0000 - val_mae: 47762.0117\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17827500032.0000 - mae: 45429.9336 - val_loss: 28469786624.0000 - val_mae: 47761.8906\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21185013760.0000 - mae: 49840.4766 - val_loss: 28469760000.0000 - val_mae: 47761.7578\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18289659904.0000 - mae: 47247.7422 - val_loss: 28469735424.0000 - val_mae: 47761.6289\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20653129728.0000 - mae: 47766.3164 - val_loss: 28469706752.0000 - val_mae: 47761.4531\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20240566272.0000 - mae: 47524.7578 - val_loss: 28469673984.0000 - val_mae: 47761.2852\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 13954571264.0000 - mae: 39526.5664 - val_loss: 28469659648.0000 - val_mae: 47761.1875\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16729916416.0000 - mae: 41227.3398 - val_loss: 28469645312.0000 - val_mae: 47761.1016\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24337301504.0000 - mae: 48979.0977 - val_loss: 28469633024.0000 - val_mae: 47761.0391\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20064434176.0000 - mae: 46852.9688 - val_loss: 28469630976.0000 - val_mae: 47761.0117\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20772294656.0000 - mae: 47122.3125 - val_loss: 28469618688.0000 - val_mae: 47760.9492\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17939152896.0000 - mae: 46784.7500 - val_loss: 28469610496.0000 - val_mae: 47760.8945\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15555665920.0000 - mae: 43648.0898 - val_loss: 28469604352.0000 - val_mae: 47760.8516\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20042745856.0000 - mae: 45583.7188 - val_loss: 28469604352.0000 - val_mae: 47760.8359\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14004044800.0000 - mae: 38000.9805 - val_loss: 28469602304.0000 - val_mae: 47760.8125\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20200427520.0000 - mae: 46810.2656 - val_loss: 28469587968.0000 - val_mae: 47760.7109\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17703682048.0000 - mae: 44705.1953 - val_loss: 28469573632.0000 - val_mae: 47760.6055\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22404212736.0000 - mae: 49258.5547 - val_loss: 28469542912.0000 - val_mae: 47760.4219\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18599616512.0000 - mae: 46957.7305 - val_loss: 28469524480.0000 - val_mae: 47760.2969\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 16175455232.0000 - mae: 43501.9297 - val_loss: 28469499904.0000 - val_mae: 47760.1836\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21222324224.0000 - mae: 48600.0430 - val_loss: 28469475328.0000 - val_mae: 47759.9961\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 14158780416.0000 - mae: 40947.0156 - val_loss: 28469448704.0000 - val_mae: 47759.8438\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 14108754944.0000 - mae: 39771.2031 - val_loss: 28469411840.0000 - val_mae: 47759.6094\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17467990016.0000 - mae: 45128.9727 - val_loss: 28469383168.0000 - val_mae: 47759.4336\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21995634688.0000 - mae: 47967.9727 - val_loss: 28469338112.0000 - val_mae: 47759.1719\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21402568704.0000 - mae: 49461.8047 - val_loss: 28469288960.0000 - val_mae: 47758.8867\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15891916800.0000 - mae: 43480.1172 - val_loss: 28469243904.0000 - val_mae: 47758.6406\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17110822912.0000 - mae: 44604.0273 - val_loss: 28469217280.0000 - val_mae: 47758.4766\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 19691540480.0000 - mae: 47915.6523 - val_loss: 28469188608.0000 - val_mae: 47758.3203\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17420075008.0000 - mae: 44103.4609 - val_loss: 28469164032.0000 - val_mae: 47758.1875\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 20313423872.0000 - mae: 50846.7812 - val_loss: 28469164032.0000 - val_mae: 47758.1641\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21600507904.0000 - mae: 49818.2656 - val_loss: 28469164032.0000 - val_mae: 47758.1289\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20111462400.0000 - mae: 45033.9414 - val_loss: 28469125120.0000 - val_mae: 47757.9141\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25047543808.0000 - mae: 52673.7617 - val_loss: 28469106688.0000 - val_mae: 47757.8242\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20524193792.0000 - mae: 48683.1719 - val_loss: 28469088256.0000 - val_mae: 47757.7305\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16964664320.0000 - mae: 43821.7461 - val_loss: 28469022720.0000 - val_mae: 47757.3438\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17342279680.0000 - mae: 45351.0391 - val_loss: 28468965376.0000 - val_mae: 47757.0352\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 20881518592.0000 - mae: 46841.9258 - val_loss: 28468926464.0000 - val_mae: 47756.7969\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17115222016.0000 - mae: 45421.6094 - val_loss: 28468897792.0000 - val_mae: 47756.5859\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26375233536.0000 - mae: 45137.5391 \n",
            "Validation Loss: 28468897792.0, Validation MAE: 47756.5859375\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Example assuming you have already loaded your dataset X (predictors) and y (targets)\n",
        "\n",
        "# 1. Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Normalize the data (important for dense networks)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# 3. Build the neural network model\n",
        "def build_model(input_dim, output_dim):\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Input Layer\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))  # To prevent overfitting\n",
        "    \n",
        "    # Hidden Layer 1\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    # Hidden Layer 2\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    # Output Layer - Regression (use 'linear' activation) or Classification (use 'softmax' for multi-class or 'sigmoid' for binary classification)\n",
        "    model.add(Dense(output_dim, activation='linear'))  # Change activation based on your task\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])  # For regression, you can change this to 'binary_crossentropy' or 'categorical_crossentropy' for classification tasks.\n",
        "    \n",
        "    return model\n",
        "\n",
        "# 4. Define input/output dimensions\n",
        "input_dim = X_train.shape[1]\n",
        "output_dim = y_train.shape[1]  # If multi-target regression, otherwise use 1\n",
        "\n",
        "# 5. Build and compile the model\n",
        "model = build_model(input_dim, output_dim)\n",
        "\n",
        "# 6. Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32)\n",
        "\n",
        "# 7. Evaluate the model\n",
        "loss, mae = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Loss: {loss}, Validation MAE: {mae}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
