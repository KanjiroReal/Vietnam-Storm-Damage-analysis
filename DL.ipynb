{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "CEPK3_hihBRf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('STORM_preprocessed_medianfill_1.csv', index_col=0) # 200 column\n",
        "evaluate_dict = dict()"
      ],
      "metadata": {
        "id": "ppt-nRO6iYj-"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, mean_absolute_error\n",
        "import numpy as np\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "def evaluate(model, X_test, y_test, threshold: float = None,\n",
        "             mode: Literal[\"classification\", \"regression\"] = \"classification\") -> dict:\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a scikit-learn model (binary classification or regression).\n",
        "\n",
        "    Args:\n",
        "        model (object): The trained model (with a predict_proba method for classification).\n",
        "        X_test (array-like): The input features for testing.\n",
        "        y_test (array-like): The true labels or values for testing.\n",
        "        threshold (float): For classification, the probability threshold. Default is 0.5.\n",
        "                           For regression, the allowed error threshold. Default is 0.2 (20%).\n",
        "        mode (Literal[\"classification\", \"regression\"]): The evaluation mode.\n",
        "            - \"classification\": Confusion matrix, accuracy, precision, recall.\n",
        "            - \"regression\": MAE, MSE, RMSE with optional tolerance check.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with relevant evaluation metrics.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the mode is invalid or threshold is not in the valid range.\n",
        "    \"\"\"\n",
        "    if threshold is None:\n",
        "        threshold = 0.5 if mode == \"classification\" else 0.2\n",
        "\n",
        "    if not (0 <= threshold <= 1):\n",
        "        raise ValueError(\"Threshold must be between 0 and 1.\")\n",
        "\n",
        "    if mode == \"classification\":\n",
        "        y_prob = model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
        "        y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        return {\n",
        "            'confusion_matrix': cm,\n",
        "            'accuracy': round(accuracy, 2),\n",
        "            'precision': round(precision, 2),\n",
        "            'recall': round(recall, 2)\n",
        "        }\n",
        "\n",
        "    elif mode == \"regression\":\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        mse = np.mean((y_test - y_pred) ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "\n",
        "        # Optional: Check if errors are within the tolerance threshold\n",
        "        tolerance_mae = threshold * np.mean(np.abs(y_test))\n",
        "        tolerance_rmse = threshold * np.std(y_test)\n",
        "        tolerance_mse = threshold * np.var(y_test)\n",
        "\n",
        "        within_tolerance = {\n",
        "            'mae_upperbound_tolerance': round(tolerance_mae - mae, 2),\n",
        "            'rmse_upperbound_tolerance': round(tolerance_rmse - rmse, 2),\n",
        "            'mse_upperbound_tolerance': round(tolerance_mse - mse, 2)\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'mae': round(mae, 2),\n",
        "            'mse': round(mse, 2),\n",
        "            'rmse': round(rmse, 2),\n",
        "            **within_tolerance\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid mode. Mode must be 'classification' or 'regression'.\")"
      ],
      "metadata": {
        "id": "uHhiXGwtofwo"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mạng Neural truyền thẳng (Feedforward NN) phù hợp cho các bài toán dự đoán nói chung.\n",
        "\n",
        "Mô hình Wide & Deep kết hợp các lớp nông và sâu để thu nhận cả các mẫu đơn giản và phức tạp.\n",
        "\n",
        "Mạng Residual (ResNet) lý tưởng cho các mô hình sâu, ngăn chặn hiện tượng mất mát gradient.\n",
        "\n",
        "Các lớp Dropout có thể giúp ngăn ngừa hiện tượng quá khớp (overfitting).\n",
        "\n",
        "TabNet là một mô hình tiên tiến được thiết kế đặc biệt cho dữ liệu bảng (tabular data), tận dụng các cơ chế attention."
      ],
      "metadata": {
        "id": "a1faU7Q2HUFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Target 1 : TotalDeaths**"
      ],
      "metadata": {
        "id": "kuFr44h5jMpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "LINEAR_TARGETS = [\"TotalDeaths\", \"NoInjured\", \"TotalDamageAdjusted(000US$)\"]\n",
        "ATTRIBUTES = ['Year', 'Month', 'MainLandfallLocation', 'OFDAResponse', 'Appeal', 'Declaration', 'LandfallMagnitude(kph)', 'LandfallPressure(mb)']\n",
        "CATEGORICAL_TARGETS = ['Flood', 'Slide']\n",
        "\n",
        "X = df[ATTRIBUTES + CATEGORICAL_TARGETS]\n",
        "y = df[LINEAR_TARGETS[0]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "zZBHiCmei0l2"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TabNet**"
      ],
      "metadata": {
        "id": "Egd9rns0m0Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW12phLun-XY",
        "outputId": "a66c7102-7197-495c-ed51-6495f67261cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Convert data to NumPy arrays (if they are not already)\n",
        "X_train_np = X_train_scaled\n",
        "X_test_np = X_test_scaled\n",
        "y_train_np = y_train.values.reshape(-1, 1)\n",
        "y_test_np = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Define the TabNet Regressor\n",
        "tabnet_model = TabNetRegressor()\n",
        "\n",
        "# Train the model with verbose set to 0\n",
        "tabnet_model.fit(\n",
        "    X_train_np, y_train_np,\n",
        "    eval_set=[(X_test_np, y_test_np)],\n",
        "    eval_metric=['rmse'],\n",
        "    max_epochs=100,\n",
        "    patience=100,\n",
        "    batch_size=32,\n",
        "    virtual_batch_size=8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4puM7fcnHwn",
        "outputId": "db745d5c-f147-4155-fb9f-b4389ba8c7dc"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 267122.69843| val_0_rmse: 612.49609|  0:00:00s\n",
            "epoch 1  | loss: 269914.55804| val_0_rmse: 611.97679|  0:00:00s\n",
            "epoch 2  | loss: 269872.83759| val_0_rmse: 611.02401|  0:00:00s\n",
            "epoch 3  | loss: 224756.34753| val_0_rmse: 610.61664|  0:00:00s\n",
            "epoch 4  | loss: 267136.87701| val_0_rmse: 609.53732|  0:00:00s\n",
            "epoch 5  | loss: 270788.83041| val_0_rmse: 608.99957|  0:00:01s\n",
            "epoch 6  | loss: 268347.09412| val_0_rmse: 608.34299|  0:00:01s\n",
            "epoch 7  | loss: 62519.61115| val_0_rmse: 608.11358|  0:00:01s\n",
            "epoch 8  | loss: 270587.23697| val_0_rmse: 607.46372|  0:00:01s\n",
            "epoch 9  | loss: 264819.9303| val_0_rmse: 607.3075|  0:00:01s\n",
            "epoch 10 | loss: 266915.5976| val_0_rmse: 606.51804|  0:00:02s\n",
            "epoch 11 | loss: 257938.85263| val_0_rmse: 607.56866|  0:00:02s\n",
            "epoch 12 | loss: 61152.13| val_0_rmse: 607.89033|  0:00:02s\n",
            "epoch 13 | loss: 255382.14185| val_0_rmse: 607.80003|  0:00:02s\n",
            "epoch 14 | loss: 264684.23071| val_0_rmse: 607.28188|  0:00:02s\n",
            "epoch 15 | loss: 254645.16235| val_0_rmse: 606.53198|  0:00:02s\n",
            "epoch 16 | loss: 257567.41333| val_0_rmse: 605.85741|  0:00:03s\n",
            "epoch 17 | loss: 252919.08496| val_0_rmse: 605.23518|  0:00:03s\n",
            "epoch 18 | loss: 246676.12543| val_0_rmse: 604.37844|  0:00:03s\n",
            "epoch 19 | loss: 245229.92188| val_0_rmse: 604.02295|  0:00:03s\n",
            "epoch 20 | loss: 204818.64978| val_0_rmse: 603.08074|  0:00:03s\n",
            "epoch 21 | loss: 55806.11292| val_0_rmse: 602.33675|  0:00:03s\n",
            "epoch 22 | loss: 54173.10461| val_0_rmse: 602.42192|  0:00:04s\n",
            "epoch 23 | loss: 51410.64734| val_0_rmse: 602.63725|  0:00:04s\n",
            "epoch 24 | loss: 232055.63672| val_0_rmse: 604.42163|  0:00:04s\n",
            "epoch 25 | loss: 231353.04309| val_0_rmse: 603.44453|  0:00:04s\n",
            "epoch 26 | loss: 230892.63965| val_0_rmse: 602.37035|  0:00:05s\n",
            "epoch 27 | loss: 224780.06055| val_0_rmse: 607.10094|  0:00:05s\n",
            "epoch 28 | loss: 226538.3811| val_0_rmse: 606.1679|  0:00:05s\n",
            "epoch 29 | loss: 222104.46826| val_0_rmse: 605.03308|  0:00:05s\n",
            "epoch 30 | loss: 223545.68896| val_0_rmse: 603.69281|  0:00:05s\n",
            "epoch 31 | loss: 219228.66016| val_0_rmse: 603.69318|  0:00:06s\n",
            "epoch 32 | loss: 239184.89722| val_0_rmse: 604.59995|  0:00:06s\n",
            "epoch 33 | loss: 225456.50244| val_0_rmse: 604.56572|  0:00:06s\n",
            "epoch 34 | loss: 223259.80591| val_0_rmse: 605.26348|  0:00:06s\n",
            "epoch 35 | loss: 217572.76941| val_0_rmse: 605.74194|  0:00:06s\n",
            "epoch 36 | loss: 213534.68848| val_0_rmse: 606.16823|  0:00:07s\n",
            "epoch 37 | loss: 235858.29785| val_0_rmse: 607.11221|  0:00:07s\n",
            "epoch 38 | loss: 237549.60022| val_0_rmse: 607.10002|  0:00:07s\n",
            "epoch 39 | loss: 52009.5249| val_0_rmse: 607.47125|  0:00:07s\n",
            "epoch 40 | loss: 228408.27637| val_0_rmse: 609.63273|  0:00:07s\n",
            "epoch 41 | loss: 46154.11841| val_0_rmse: 610.41904|  0:00:08s\n",
            "epoch 42 | loss: 219697.80273| val_0_rmse: 610.39175|  0:00:08s\n",
            "epoch 43 | loss: 246877.18359| val_0_rmse: 610.90444|  0:00:08s\n",
            "epoch 44 | loss: 214641.04956| val_0_rmse: 610.60147|  0:00:08s\n",
            "epoch 45 | loss: 212712.42969| val_0_rmse: 605.23702|  0:00:08s\n",
            "epoch 46 | loss: 211929.93018| val_0_rmse: 605.65216|  0:00:08s\n",
            "epoch 47 | loss: 235495.60999| val_0_rmse: 606.22786|  0:00:08s\n",
            "epoch 48 | loss: 220237.98535| val_0_rmse: 604.95175|  0:00:09s\n",
            "epoch 49 | loss: 249479.22412| val_0_rmse: 604.74746|  0:00:09s\n",
            "epoch 50 | loss: 209308.67456| val_0_rmse: 604.13492|  0:00:09s\n",
            "epoch 51 | loss: 41864.45404| val_0_rmse: 603.62351|  0:00:09s\n",
            "epoch 52 | loss: 43372.09003| val_0_rmse: 605.65267|  0:00:09s\n",
            "epoch 53 | loss: 212450.79639| val_0_rmse: 606.19818|  0:00:09s\n",
            "epoch 54 | loss: 211829.875| val_0_rmse: 604.02011|  0:00:09s\n",
            "epoch 55 | loss: 204362.92664| val_0_rmse: 603.4072|  0:00:10s\n",
            "epoch 56 | loss: 204365.99072| val_0_rmse: 603.2668|  0:00:10s\n",
            "epoch 57 | loss: 210354.46191| val_0_rmse: 602.90366|  0:00:10s\n",
            "epoch 58 | loss: 207985.52917| val_0_rmse: 604.9188|  0:00:10s\n",
            "epoch 59 | loss: 206869.56934| val_0_rmse: 605.19087|  0:00:10s\n",
            "epoch 60 | loss: 46322.67224| val_0_rmse: 605.11877|  0:00:10s\n",
            "epoch 61 | loss: 56837.69434| val_0_rmse: 605.45685|  0:00:10s\n",
            "epoch 62 | loss: 215755.08911| val_0_rmse: 605.77013|  0:00:11s\n",
            "epoch 63 | loss: 237333.39978| val_0_rmse: 604.9499|  0:00:11s\n",
            "epoch 64 | loss: 215469.66724| val_0_rmse: 604.63887|  0:00:11s\n",
            "epoch 65 | loss: 194888.9314| val_0_rmse: 603.15961|  0:00:11s\n",
            "epoch 66 | loss: 231203.10754| val_0_rmse: 603.53961|  0:00:11s\n",
            "epoch 67 | loss: 244204.12756| val_0_rmse: 601.06453|  0:00:11s\n",
            "epoch 68 | loss: 247896.5575| val_0_rmse: 598.10738|  0:00:12s\n",
            "epoch 69 | loss: 53672.87036| val_0_rmse: 597.76718|  0:00:12s\n",
            "epoch 70 | loss: 237942.93945| val_0_rmse: 598.38565|  0:00:12s\n",
            "epoch 71 | loss: 238553.03076| val_0_rmse: 599.14138|  0:00:12s\n",
            "epoch 72 | loss: 237887.3761| val_0_rmse: 604.87023|  0:00:12s\n",
            "epoch 73 | loss: 234616.87817| val_0_rmse: 607.13114|  0:00:12s\n",
            "epoch 74 | loss: 237383.61707| val_0_rmse: 606.90558|  0:00:13s\n",
            "epoch 75 | loss: 54660.67706| val_0_rmse: 607.54352|  0:00:13s\n",
            "epoch 76 | loss: 225534.79395| val_0_rmse: 606.93379|  0:00:13s\n",
            "epoch 77 | loss: 227295.92578| val_0_rmse: 605.47081|  0:00:13s\n",
            "epoch 78 | loss: 231621.3252| val_0_rmse: 604.53305|  0:00:13s\n",
            "epoch 79 | loss: 218418.64917| val_0_rmse: 604.65196|  0:00:13s\n",
            "epoch 80 | loss: 222662.87964| val_0_rmse: 603.48237|  0:00:13s\n",
            "epoch 81 | loss: 212947.16553| val_0_rmse: 603.72641|  0:00:14s\n",
            "epoch 82 | loss: 216080.40967| val_0_rmse: 603.54552|  0:00:14s\n",
            "epoch 83 | loss: 228565.24756| val_0_rmse: 596.83123|  0:00:14s\n",
            "epoch 84 | loss: 207530.56104| val_0_rmse: 603.98148|  0:00:14s\n",
            "epoch 85 | loss: 204467.12543| val_0_rmse: 603.67275|  0:00:14s\n",
            "epoch 86 | loss: 211213.7417| val_0_rmse: 603.98805|  0:00:14s\n",
            "epoch 87 | loss: 178720.20288| val_0_rmse: 604.74037|  0:00:15s\n",
            "epoch 88 | loss: 201471.58423| val_0_rmse: 605.55974|  0:00:15s\n",
            "epoch 89 | loss: 172983.14844| val_0_rmse: 605.41784|  0:00:15s\n",
            "epoch 90 | loss: 228916.49341| val_0_rmse: 602.64962|  0:00:15s\n",
            "epoch 91 | loss: 171191.021| val_0_rmse: 606.04746|  0:00:15s\n",
            "epoch 92 | loss: 195323.04492| val_0_rmse: 605.0249|  0:00:15s\n",
            "epoch 93 | loss: 200513.44995| val_0_rmse: 603.44353|  0:00:15s\n",
            "epoch 94 | loss: 195599.23486| val_0_rmse: 608.53509|  0:00:16s\n",
            "epoch 95 | loss: 196344.20288| val_0_rmse: 608.9766|  0:00:16s\n",
            "epoch 96 | loss: 34931.8313| val_0_rmse: 614.35419|  0:00:16s\n",
            "epoch 97 | loss: 212020.0874| val_0_rmse: 612.75113|  0:00:16s\n",
            "epoch 98 | loss: 15635.52942| val_0_rmse: 606.96107|  0:00:16s\n",
            "epoch 99 | loss: 215692.1712| val_0_rmse: 606.60929|  0:00:16s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 83 and best_val_0_rmse = 596.83123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(tabnet_model, X_test_np, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict = {}\n",
        "evaluate_dict[\"TabNet\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aKmijHWE6Px",
        "outputId": "bd38f02c-8242-425d-fc4d-a43ac8e1c572"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 151.39,\n",
              " 'mse': 356207.52,\n",
              " 'rmse': 596.83,\n",
              " 'mae_upperbound_tolerance': -107.23,\n",
              " 'rmse_upperbound_tolerance': -418.25,\n",
              " 'mse_upperbound_tolerance': -249900.43}"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**"
      ],
      "metadata": {
        "id": "-DoMqm61wcy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "-PoqYrJ4wNzQ"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, units):\n",
        "    shortcut = x\n",
        "    x = layers.Dense(units, activation='relu')(x)\n",
        "    x = layers.Dense(units)(x)  # No activation for the second layer\n",
        "    x = layers.add([x, shortcut])  # Add the shortcut\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_resnet(input_shape, output_units):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add several residual blocks\n",
        "    for _ in range(3):  # Adjust the number of blocks as needed\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    outputs = layers.Dense(output_units)(x)  # For regression, no activation here\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "resnet_model = build_resnet(input_shape=(X_train_scaled.shape[1],), output_units=1)\n",
        "resnet_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
        "\n",
        "resnet_model.fit(X_train_scaled, y_train_np, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_np), callbacks=[checkpoint], verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgsT-glJvicR",
        "outputId": "45a40988-1ce8-4199-8ed5-6358cef36177"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x797300d786a0>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(resnet_model, X_test_scaled, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"ResNet\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cih7FdU4wtqn",
        "outputId": "6a8824d3-9875-45cf-e87e-0b608f84ac7a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 159.28,\n",
              " 'mse': 375273.13,\n",
              " 'rmse': 612.6,\n",
              " 'mae_upperbound_tolerance': -115.13,\n",
              " 'rmse_upperbound_tolerance': -434.01,\n",
              " 'mse_upperbound_tolerance': -268966.04}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wide & Deep Model**"
      ],
      "metadata": {
        "id": "_Buq0aNn30Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import concatenate, Input, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "-gZZgVZO37yH"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "# Wide part (linear connection)\n",
        "wide_layer = Dense(1, activation='linear')(input_layer)\n",
        "\n",
        "# Deep part\n",
        "deep_layer = Dense(128, activation='relu')(input_layer)\n",
        "deep_layer = Dense(64, activation='relu')(deep_layer)\n",
        "deep_layer = Dense(32, activation='relu')(deep_layer)\n",
        "\n",
        "# Combine Wide and Deep parts\n",
        "combined = concatenate([wide_layer, deep_layer])\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation='linear')(combined)\n",
        "\n",
        "# Build and compile the model\n",
        "deep_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "deep_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "deep_model.fit(X_train_scaled, y_train_np, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_np), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tvc_bV7329Z",
        "outputId": "d228d62f-8785-433c-a1f8-b58ff17286e6"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972fd114eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(deep_model, X_test_scaled, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"Wide & Deep Model\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlEby8414Nw2",
        "outputId": "74982470-d3bf-451d-a491-f3c18458b6bc"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 162.67,\n",
              " 'mse': 388620.51,\n",
              " 'rmse': 623.39,\n",
              " 'mae_upperbound_tolerance': -118.51,\n",
              " 'rmse_upperbound_tolerance': -444.81,\n",
              " 'mse_upperbound_tolerance': -282313.42}"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "IZaqw9CC6v25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "wOnzPY_IE5lo"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for LSTM\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y.iloc[i + time_steps])  # Corresponding y value\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "TIME_STEPS = 1  # You can change this value based on your needs\n",
        "X_train_lstm, y_train_lstm = create_dataset(pd.DataFrame(X_train_scaled), pd.Series(y_train), TIME_STEPS)\n",
        "X_test_lstm, y_test_lstm = create_dataset(pd.DataFrame(X_test_scaled), pd.Series(y_test), TIME_STEPS)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
        "X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2]))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))  # Output layer for regression (adjust this based on the number of targets)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_lstm, y_train_lstm, epochs=100, batch_size=32, validation_data=(X_test_lstm, y_test_lstm), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUiNFT7nE2Co",
        "outputId": "b59f0392-1c37-4ec9-8211-ba6d8778df0b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972fce59e10>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(model, X_test_lstm, y_test_lstm, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"LSTM\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Y2WbQOFHcm",
        "outputId": "735923cf-cef7-4d57-d0a7-d477edf9c176"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 144.85,\n",
              " 'mse': 381573.82,\n",
              " 'rmse': 617.72,\n",
              " 'mae_upperbound_tolerance': -100.35,\n",
              " 'rmse_upperbound_tolerance': -436.68,\n",
              " 'mse_upperbound_tolerance': -272328.29}"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare metrics value\n",
        "def highlight_max(s):\n",
        "    is_max = s == s.max()\n",
        "    return ['color: red' if v else '' for v in is_max]\n",
        "\n",
        "def highlight_min(s):\n",
        "    is_min = s == s.min()\n",
        "    return ['color: red' if v else '' for v in is_min]\n",
        "\n",
        "def highlight_row(row, selected_method):\n",
        "    return ['background-color: black;' if row['Method'] in selected_method else ''\n",
        "            for _ in row]\n",
        "\n",
        "selected_method = [model.__class__.__name__]\n",
        "eval_value_df = pd.DataFrame(evaluate_dict).T.reset_index().rename(columns={\"index\":\"Method\"})\n",
        "\n",
        "eval_value_df = (\n",
        "    eval_value_df.style\n",
        "    .apply(highlight_max, subset=[\"mae_upperbound_tolerance\", \"rmse_upperbound_tolerance\", \"mse_upperbound_tolerance\"])\n",
        "    .apply(highlight_min, subset=[\"mae\", \"mse\", \"rmse\"])\n",
        "    .apply(lambda row: highlight_row(row, selected_method), axis=1 )\n",
        "    .format(precision=2)\n",
        ")\n",
        "\n",
        "eval_value_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Ujlhh40euzAT",
        "outputId": "e835ab0d-cbbc-4acc-831e-d545481b52a0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7972fce49390>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_45d14_row0_col2, #T_45d14_row0_col3, #T_45d14_row0_col5, #T_45d14_row0_col6, #T_45d14_row3_col1, #T_45d14_row3_col4 {\n",
              "  color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_45d14\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_45d14_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
              "      <th id=\"T_45d14_level0_col1\" class=\"col_heading level0 col1\" >mae</th>\n",
              "      <th id=\"T_45d14_level0_col2\" class=\"col_heading level0 col2\" >mse</th>\n",
              "      <th id=\"T_45d14_level0_col3\" class=\"col_heading level0 col3\" >rmse</th>\n",
              "      <th id=\"T_45d14_level0_col4\" class=\"col_heading level0 col4\" >mae_upperbound_tolerance</th>\n",
              "      <th id=\"T_45d14_level0_col5\" class=\"col_heading level0 col5\" >rmse_upperbound_tolerance</th>\n",
              "      <th id=\"T_45d14_level0_col6\" class=\"col_heading level0 col6\" >mse_upperbound_tolerance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_45d14_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_45d14_row0_col0\" class=\"data row0 col0\" >TabNet</td>\n",
              "      <td id=\"T_45d14_row0_col1\" class=\"data row0 col1\" >151.39</td>\n",
              "      <td id=\"T_45d14_row0_col2\" class=\"data row0 col2\" >356207.52</td>\n",
              "      <td id=\"T_45d14_row0_col3\" class=\"data row0 col3\" >596.83</td>\n",
              "      <td id=\"T_45d14_row0_col4\" class=\"data row0 col4\" >-107.23</td>\n",
              "      <td id=\"T_45d14_row0_col5\" class=\"data row0 col5\" >-418.25</td>\n",
              "      <td id=\"T_45d14_row0_col6\" class=\"data row0 col6\" >-249900.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_45d14_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_45d14_row1_col0\" class=\"data row1 col0\" >ResNet</td>\n",
              "      <td id=\"T_45d14_row1_col1\" class=\"data row1 col1\" >159.28</td>\n",
              "      <td id=\"T_45d14_row1_col2\" class=\"data row1 col2\" >375273.13</td>\n",
              "      <td id=\"T_45d14_row1_col3\" class=\"data row1 col3\" >612.60</td>\n",
              "      <td id=\"T_45d14_row1_col4\" class=\"data row1 col4\" >-115.13</td>\n",
              "      <td id=\"T_45d14_row1_col5\" class=\"data row1 col5\" >-434.01</td>\n",
              "      <td id=\"T_45d14_row1_col6\" class=\"data row1 col6\" >-268966.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_45d14_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_45d14_row2_col0\" class=\"data row2 col0\" >Wide & Deep Model</td>\n",
              "      <td id=\"T_45d14_row2_col1\" class=\"data row2 col1\" >162.67</td>\n",
              "      <td id=\"T_45d14_row2_col2\" class=\"data row2 col2\" >388620.51</td>\n",
              "      <td id=\"T_45d14_row2_col3\" class=\"data row2 col3\" >623.39</td>\n",
              "      <td id=\"T_45d14_row2_col4\" class=\"data row2 col4\" >-118.51</td>\n",
              "      <td id=\"T_45d14_row2_col5\" class=\"data row2 col5\" >-444.81</td>\n",
              "      <td id=\"T_45d14_row2_col6\" class=\"data row2 col6\" >-282313.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_45d14_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_45d14_row3_col0\" class=\"data row3 col0\" >LSTM</td>\n",
              "      <td id=\"T_45d14_row3_col1\" class=\"data row3 col1\" >144.85</td>\n",
              "      <td id=\"T_45d14_row3_col2\" class=\"data row3 col2\" >381573.82</td>\n",
              "      <td id=\"T_45d14_row3_col3\" class=\"data row3 col3\" >617.72</td>\n",
              "      <td id=\"T_45d14_row3_col4\" class=\"data row3 col4\" >-100.35</td>\n",
              "      <td id=\"T_45d14_row3_col5\" class=\"data row3 col5\" >-436.68</td>\n",
              "      <td id=\"T_45d14_row3_col6\" class=\"data row3 col6\" >-272328.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Target 2 : NoInjured**"
      ],
      "metadata": {
        "id": "tK8WWhA7GlL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LINEAR_TARGETS = [\"TotalDeaths\", \"NoInjured\", \"TotalDamageAdjusted(000US$)\"]\n",
        "ATTRIBUTES = ['Year', 'Month', 'MainLandfallLocation', 'OFDAResponse', 'Appeal', 'Declaration', 'LandfallMagnitude(kph)', 'LandfallPressure(mb)']\n",
        "CATEGORICAL_TARGETS = ['Flood', 'Slide']\n",
        "\n",
        "X = df[ATTRIBUTES + CATEGORICAL_TARGETS]\n",
        "y = df[LINEAR_TARGETS[1]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7nDb17DIGveo"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TabNet**"
      ],
      "metadata": {
        "id": "23NDk8RjzFl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Convert data to NumPy arrays (if they are not already)\n",
        "X_train_np = X_train_scaled\n",
        "X_test_np = X_test_scaled\n",
        "y_train_np = y_train.values.reshape(-1, 1)\n",
        "y_test_np = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Define the TabNet Regressor\n",
        "tabnet_model = TabNetRegressor()\n",
        "\n",
        "# Train the model with verbose set to 0\n",
        "tabnet_model.fit(\n",
        "    X_train_np, y_train_np,\n",
        "    eval_set=[(X_test_np, y_test_np)],\n",
        "    eval_metric=['rmse'],\n",
        "    max_epochs=100,\n",
        "    patience=100,\n",
        "    batch_size=32,\n",
        "    virtual_batch_size=8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k993xgTmHRnv",
        "outputId": "1ceb5d1b-400b-4b00-f0de-ca79553093e8"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 41342.91809| val_0_rmse: 457.48739|  0:00:00s\n",
            "epoch 1  | loss: 40483.16895| val_0_rmse: 457.41892|  0:00:00s\n",
            "epoch 2  | loss: 30989.36633| val_0_rmse: 456.37871|  0:00:00s\n",
            "epoch 3  | loss: 39795.71899| val_0_rmse: 454.79109|  0:00:00s\n",
            "epoch 4  | loss: 38749.64453| val_0_rmse: 453.96837|  0:00:00s\n",
            "epoch 5  | loss: 37853.73267| val_0_rmse: 453.16265|  0:00:00s\n",
            "epoch 6  | loss: 38109.79175| val_0_rmse: 450.33838|  0:00:01s\n",
            "epoch 7  | loss: 37540.91101| val_0_rmse: 451.09755|  0:00:01s\n",
            "epoch 8  | loss: 35628.43921| val_0_rmse: 449.84134|  0:00:01s\n",
            "epoch 9  | loss: 23545.63745| val_0_rmse: 448.97983|  0:00:01s\n",
            "epoch 10 | loss: 35801.52747| val_0_rmse: 446.69131|  0:00:01s\n",
            "epoch 11 | loss: 21865.74988| val_0_rmse: 444.70022|  0:00:01s\n",
            "epoch 12 | loss: 34280.8114| val_0_rmse: 439.59275|  0:00:01s\n",
            "epoch 13 | loss: 33762.63684| val_0_rmse: 436.90352|  0:00:02s\n",
            "epoch 14 | loss: 32441.63953| val_0_rmse: 432.77404|  0:00:02s\n",
            "epoch 15 | loss: 32575.72107| val_0_rmse: 433.4502|  0:00:02s\n",
            "epoch 16 | loss: 31298.56348| val_0_rmse: 431.87659|  0:00:02s\n",
            "epoch 17 | loss: 19649.52563| val_0_rmse: 440.90982|  0:00:02s\n",
            "epoch 18 | loss: 31735.58923| val_0_rmse: 428.38068|  0:00:02s\n",
            "epoch 19 | loss: 30592.77783| val_0_rmse: 428.97951|  0:00:02s\n",
            "epoch 20 | loss: 17153.05029| val_0_rmse: 427.74486|  0:00:03s\n",
            "epoch 21 | loss: 27342.28076| val_0_rmse: 425.18189|  0:00:03s\n",
            "epoch 22 | loss: 27837.69165| val_0_rmse: 422.66063|  0:00:03s\n",
            "epoch 23 | loss: 28924.50562| val_0_rmse: 422.26955|  0:00:03s\n",
            "epoch 24 | loss: 31467.81567| val_0_rmse: 421.75078|  0:00:03s\n",
            "epoch 25 | loss: 28636.29932| val_0_rmse: 430.99184|  0:00:03s\n",
            "epoch 26 | loss: 29448.95166| val_0_rmse: 432.43482|  0:00:04s\n",
            "epoch 27 | loss: 15570.43347| val_0_rmse: 434.26871|  0:00:04s\n",
            "epoch 28 | loss: 19746.62207| val_0_rmse: 432.72553|  0:00:04s\n",
            "epoch 29 | loss: 21027.12488| val_0_rmse: 433.61339|  0:00:04s\n",
            "epoch 30 | loss: 30496.85339| val_0_rmse: 433.3975|  0:00:04s\n",
            "epoch 31 | loss: 30493.22388| val_0_rmse: 433.56512|  0:00:04s\n",
            "epoch 32 | loss: 29804.14331| val_0_rmse: 433.63908|  0:00:04s\n",
            "epoch 33 | loss: 29055.99658| val_0_rmse: 436.51553|  0:00:05s\n",
            "epoch 34 | loss: 24256.8623| val_0_rmse: 433.05647|  0:00:05s\n",
            "epoch 35 | loss: 27583.55969| val_0_rmse: 433.74468|  0:00:05s\n",
            "epoch 36 | loss: 27828.65662| val_0_rmse: 431.91918|  0:00:05s\n",
            "epoch 37 | loss: 30708.40375| val_0_rmse: 430.71182|  0:00:05s\n",
            "epoch 38 | loss: 20985.96924| val_0_rmse: 431.64354|  0:00:06s\n",
            "epoch 39 | loss: 28062.526| val_0_rmse: 431.37234|  0:00:06s\n",
            "epoch 40 | loss: 26125.85938| val_0_rmse: 431.49294|  0:00:06s\n",
            "epoch 41 | loss: 29802.54309| val_0_rmse: 436.35842|  0:00:06s\n",
            "epoch 42 | loss: 30610.52698| val_0_rmse: 437.41803|  0:00:06s\n",
            "epoch 43 | loss: 30213.22253| val_0_rmse: 437.33534|  0:00:07s\n",
            "epoch 44 | loss: 30983.64087| val_0_rmse: 438.5892|  0:00:07s\n",
            "epoch 45 | loss: 30958.1106| val_0_rmse: 438.76961|  0:00:07s\n",
            "epoch 46 | loss: 29606.46997| val_0_rmse: 438.96291|  0:00:07s\n",
            "epoch 47 | loss: 30649.19177| val_0_rmse: 434.54048|  0:00:07s\n",
            "epoch 48 | loss: 27863.90796| val_0_rmse: 430.87843|  0:00:08s\n",
            "epoch 49 | loss: 26430.70508| val_0_rmse: 427.38613|  0:00:08s\n",
            "epoch 50 | loss: 23725.66138| val_0_rmse: 425.59568|  0:00:08s\n",
            "epoch 51 | loss: 26646.22894| val_0_rmse: 426.39044|  0:00:08s\n",
            "epoch 52 | loss: 32423.86682| val_0_rmse: 423.61171|  0:00:08s\n",
            "epoch 53 | loss: 15234.18665| val_0_rmse: 426.911 |  0:00:09s\n",
            "epoch 54 | loss: 30920.8855| val_0_rmse: 428.70745|  0:00:09s\n",
            "epoch 55 | loss: 24025.96716| val_0_rmse: 429.23973|  0:00:09s\n",
            "epoch 56 | loss: 29528.72217| val_0_rmse: 427.93663|  0:00:09s\n",
            "epoch 57 | loss: 30193.56055| val_0_rmse: 428.60052|  0:00:09s\n",
            "epoch 58 | loss: 29185.69727| val_0_rmse: 429.13252|  0:00:09s\n",
            "epoch 59 | loss: 23105.91406| val_0_rmse: 428.9133|  0:00:10s\n",
            "epoch 60 | loss: 23522.74731| val_0_rmse: 427.99079|  0:00:10s\n",
            "epoch 61 | loss: 26980.34326| val_0_rmse: 428.20909|  0:00:10s\n",
            "epoch 62 | loss: 29952.32312| val_0_rmse: 429.96409|  0:00:10s\n",
            "epoch 63 | loss: 28650.74854| val_0_rmse: 429.73561|  0:00:10s\n",
            "epoch 64 | loss: 27828.46057| val_0_rmse: 429.46187|  0:00:10s\n",
            "epoch 65 | loss: 29455.72498| val_0_rmse: 428.5218|  0:00:10s\n",
            "epoch 66 | loss: 30017.47034| val_0_rmse: 429.57761|  0:00:10s\n",
            "epoch 67 | loss: 30591.34314| val_0_rmse: 429.51214|  0:00:11s\n",
            "epoch 68 | loss: 28279.78534| val_0_rmse: 430.15846|  0:00:11s\n",
            "epoch 69 | loss: 26554.03296| val_0_rmse: 430.94054|  0:00:11s\n",
            "epoch 70 | loss: 28906.87512| val_0_rmse: 435.45806|  0:00:11s\n",
            "epoch 71 | loss: 25866.05176| val_0_rmse: 439.21953|  0:00:11s\n",
            "epoch 72 | loss: 28705.96289| val_0_rmse: 436.86027|  0:00:11s\n",
            "epoch 73 | loss: 27178.17853| val_0_rmse: 433.45063|  0:00:11s\n",
            "epoch 74 | loss: 29667.2749| val_0_rmse: 429.53855|  0:00:12s\n",
            "epoch 75 | loss: 27402.20618| val_0_rmse: 427.46966|  0:00:12s\n",
            "epoch 76 | loss: 19243.99609| val_0_rmse: 429.18719|  0:00:12s\n",
            "epoch 77 | loss: 28956.03931| val_0_rmse: 430.46922|  0:00:12s\n",
            "epoch 78 | loss: 30056.84546| val_0_rmse: 432.03327|  0:00:12s\n",
            "epoch 79 | loss: 32430.70898| val_0_rmse: 431.91994|  0:00:12s\n",
            "epoch 80 | loss: 27846.96362| val_0_rmse: 433.42533|  0:00:12s\n",
            "epoch 81 | loss: 29639.44836| val_0_rmse: 434.77361|  0:00:13s\n",
            "epoch 82 | loss: 21282.5603| val_0_rmse: 434.13841|  0:00:13s\n",
            "epoch 83 | loss: 32323.97278| val_0_rmse: 434.21489|  0:00:13s\n",
            "epoch 84 | loss: 17577.36731| val_0_rmse: 434.07795|  0:00:13s\n",
            "epoch 85 | loss: 28654.3916| val_0_rmse: 434.49861|  0:00:13s\n",
            "epoch 86 | loss: 22448.198| val_0_rmse: 434.52334|  0:00:13s\n",
            "epoch 87 | loss: 25310.01892| val_0_rmse: 434.55538|  0:00:13s\n",
            "epoch 88 | loss: 16851.52698| val_0_rmse: 435.34301|  0:00:13s\n",
            "epoch 89 | loss: 23546.52856| val_0_rmse: 435.46124|  0:00:14s\n",
            "epoch 90 | loss: 30414.88147| val_0_rmse: 436.58713|  0:00:14s\n",
            "epoch 91 | loss: 29786.56683| val_0_rmse: 434.41755|  0:00:14s\n",
            "epoch 92 | loss: 28959.13458| val_0_rmse: 430.28211|  0:00:14s\n",
            "epoch 93 | loss: 21539.47522| val_0_rmse: 428.83742|  0:00:14s\n",
            "epoch 94 | loss: 28273.75464| val_0_rmse: 428.27352|  0:00:14s\n",
            "epoch 95 | loss: 16187.89844| val_0_rmse: 425.60544|  0:00:14s\n",
            "epoch 96 | loss: 22537.28223| val_0_rmse: 424.16714|  0:00:15s\n",
            "epoch 97 | loss: 28002.03802| val_0_rmse: 425.15598|  0:00:15s\n",
            "epoch 98 | loss: 17274.30249| val_0_rmse: 426.89569|  0:00:15s\n",
            "epoch 99 | loss: 26062.97601| val_0_rmse: 427.57546|  0:00:15s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 24 and best_val_0_rmse = 421.75078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(tabnet_model, X_test_np, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict = {}\n",
        "evaluate_dict[\"TabNet\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnNoTqhKHhwI",
        "outputId": "bb320e74-2a19-4ba5-9758-7e544876e6ab"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 134.44,\n",
              " 'mse': 177873.72,\n",
              " 'rmse': 421.75,\n",
              " 'mae_upperbound_tolerance': -93.88,\n",
              " 'rmse_upperbound_tolerance': -290.38,\n",
              " 'mse_upperbound_tolerance': -120345.95}"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**"
      ],
      "metadata": {
        "id": "S1qM7N4Ux48L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, units):\n",
        "    shortcut = x\n",
        "    x = layers.Dense(units, activation='relu')(x)\n",
        "    x = layers.Dense(units)(x)  # No activation for the second layer\n",
        "    x = layers.add([x, shortcut])  # Add the shortcut\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_resnet(input_shape, output_units):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add several residual blocks\n",
        "    for _ in range(3):  # Adjust the number of blocks as needed\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    outputs = layers.Dense(output_units)(x)  # For regression, no activation here\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "resnet_model = build_resnet(input_shape=(X_train_scaled.shape[1],), output_units=1)\n",
        "resnet_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
        "\n",
        "resnet_model.fit(X_train_scaled, y_train_np, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_np), callbacks=[checkpoint], verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpUIFeqfx898",
        "outputId": "6e32cfe4-786c-45a0-b98e-f161cf8fe8a1"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972fa957460>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(resnet_model, X_test_scaled, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"ResNet\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LInkQlhRySzJ",
        "outputId": "093d78be-b012-4c85-bb3f-43949f2fc407"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 152.35,\n",
              " 'mse': 202205.47,\n",
              " 'rmse': 449.67,\n",
              " 'mae_upperbound_tolerance': -111.8,\n",
              " 'rmse_upperbound_tolerance': -318.3,\n",
              " 'mse_upperbound_tolerance': -144677.7}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wide & Deep Model**"
      ],
      "metadata": {
        "id": "vBIncazYyUyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "# Wide part (linear connection)\n",
        "wide_layer = Dense(1, activation='linear')(input_layer)\n",
        "\n",
        "# Deep part\n",
        "deep_layer = Dense(128, activation='relu')(input_layer)\n",
        "deep_layer = Dense(64, activation='relu')(deep_layer)\n",
        "deep_layer = Dense(32, activation='relu')(deep_layer)\n",
        "\n",
        "# Combine Wide and Deep parts\n",
        "combined = concatenate([wide_layer, deep_layer])\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation='linear')(combined)\n",
        "\n",
        "# Build and compile the model\n",
        "deep_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "deep_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "deep_model.fit(X_train_scaled, y_train_np, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_np), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv83sUivyYLz",
        "outputId": "c54c9909-1fa4-4117-add8-ef7462dc5007"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972fa4af580>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(deep_model, X_test_scaled, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"Wide & Deep Model\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uojYrUE2yfK6",
        "outputId": "ce9aacb3-1561-4d47-c894-d246148c5149"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 131.23,\n",
              " 'mse': 176558.92,\n",
              " 'rmse': 420.19,\n",
              " 'mae_upperbound_tolerance': -90.68,\n",
              " 'rmse_upperbound_tolerance': -288.82,\n",
              " 'mse_upperbound_tolerance': -119031.14}"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "XSRGFMTOykFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for LSTM\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y.iloc[i + time_steps])  # Corresponding y value\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "TIME_STEPS = 1  # You can change this value based on your needs\n",
        "X_train_lstm, y_train_lstm = create_dataset(pd.DataFrame(X_train_scaled), pd.Series(y_train), TIME_STEPS)\n",
        "X_test_lstm, y_test_lstm = create_dataset(pd.DataFrame(X_test_scaled), pd.Series(y_test), TIME_STEPS)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
        "X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2]))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))  # Output layer for regression (adjust this based on the number of targets)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_lstm, y_train_lstm, epochs=100, batch_size=32, validation_data=(X_test_lstm, y_test_lstm), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lvHQX96ylny",
        "outputId": "a7d70c9c-374a-41c3-e053-7d1458e7f17e"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972f89f0fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(model, X_test_lstm, y_test_lstm, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"LSTM\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrJOug6Uyxi6",
        "outputId": "47997b3f-ed9f-49a4-9243-c50a24c0908f"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 133.08,\n",
              " 'mse': 211609.92,\n",
              " 'rmse': 460.01,\n",
              " 'mae_upperbound_tolerance': -91.56,\n",
              " 'rmse_upperbound_tolerance': -326.96,\n",
              " 'mse_upperbound_tolerance': -152597.8}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare metrics value\n",
        "def highlight_max(s):\n",
        "    is_max = s == s.max()\n",
        "    return ['color: red' if v else '' for v in is_max]\n",
        "\n",
        "def highlight_min(s):\n",
        "    is_min = s == s.min()\n",
        "    return ['color: red' if v else '' for v in is_min]\n",
        "\n",
        "def highlight_row(row, selected_method):\n",
        "    return ['background-color: black;' if row['Method'] in selected_method else ''\n",
        "            for _ in row]\n",
        "\n",
        "selected_method = [model.__class__.__name__]\n",
        "eval_value_df = pd.DataFrame(evaluate_dict).T.reset_index().rename(columns={\"index\":\"Method\"})\n",
        "\n",
        "eval_value_df = (\n",
        "    eval_value_df.style\n",
        "    .apply(highlight_max, subset=[\"mae_upperbound_tolerance\", \"rmse_upperbound_tolerance\", \"mse_upperbound_tolerance\"])\n",
        "    .apply(highlight_min, subset=[\"mae\", \"mse\", \"rmse\"])\n",
        "    .apply(lambda row: highlight_row(row, selected_method), axis=1 )\n",
        "    .format(precision=2)\n",
        ")\n",
        "\n",
        "eval_value_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Yw95neRXy4Y7",
        "outputId": "33b2c672-9cdb-4e7c-adc5-fac4b97046b8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7972fcfcbd90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_81439_row2_col1, #T_81439_row2_col2, #T_81439_row2_col3, #T_81439_row2_col4, #T_81439_row2_col5, #T_81439_row2_col6 {\n",
              "  color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_81439\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_81439_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
              "      <th id=\"T_81439_level0_col1\" class=\"col_heading level0 col1\" >mae</th>\n",
              "      <th id=\"T_81439_level0_col2\" class=\"col_heading level0 col2\" >mse</th>\n",
              "      <th id=\"T_81439_level0_col3\" class=\"col_heading level0 col3\" >rmse</th>\n",
              "      <th id=\"T_81439_level0_col4\" class=\"col_heading level0 col4\" >mae_upperbound_tolerance</th>\n",
              "      <th id=\"T_81439_level0_col5\" class=\"col_heading level0 col5\" >rmse_upperbound_tolerance</th>\n",
              "      <th id=\"T_81439_level0_col6\" class=\"col_heading level0 col6\" >mse_upperbound_tolerance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_81439_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_81439_row0_col0\" class=\"data row0 col0\" >TabNet</td>\n",
              "      <td id=\"T_81439_row0_col1\" class=\"data row0 col1\" >134.44</td>\n",
              "      <td id=\"T_81439_row0_col2\" class=\"data row0 col2\" >177873.72</td>\n",
              "      <td id=\"T_81439_row0_col3\" class=\"data row0 col3\" >421.75</td>\n",
              "      <td id=\"T_81439_row0_col4\" class=\"data row0 col4\" >-93.88</td>\n",
              "      <td id=\"T_81439_row0_col5\" class=\"data row0 col5\" >-290.38</td>\n",
              "      <td id=\"T_81439_row0_col6\" class=\"data row0 col6\" >-120345.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81439_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_81439_row1_col0\" class=\"data row1 col0\" >ResNet</td>\n",
              "      <td id=\"T_81439_row1_col1\" class=\"data row1 col1\" >152.35</td>\n",
              "      <td id=\"T_81439_row1_col2\" class=\"data row1 col2\" >202205.47</td>\n",
              "      <td id=\"T_81439_row1_col3\" class=\"data row1 col3\" >449.67</td>\n",
              "      <td id=\"T_81439_row1_col4\" class=\"data row1 col4\" >-111.80</td>\n",
              "      <td id=\"T_81439_row1_col5\" class=\"data row1 col5\" >-318.30</td>\n",
              "      <td id=\"T_81439_row1_col6\" class=\"data row1 col6\" >-144677.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81439_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_81439_row2_col0\" class=\"data row2 col0\" >Wide & Deep Model</td>\n",
              "      <td id=\"T_81439_row2_col1\" class=\"data row2 col1\" >131.23</td>\n",
              "      <td id=\"T_81439_row2_col2\" class=\"data row2 col2\" >176558.92</td>\n",
              "      <td id=\"T_81439_row2_col3\" class=\"data row2 col3\" >420.19</td>\n",
              "      <td id=\"T_81439_row2_col4\" class=\"data row2 col4\" >-90.68</td>\n",
              "      <td id=\"T_81439_row2_col5\" class=\"data row2 col5\" >-288.82</td>\n",
              "      <td id=\"T_81439_row2_col6\" class=\"data row2 col6\" >-119031.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81439_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_81439_row3_col0\" class=\"data row3 col0\" >LSTM</td>\n",
              "      <td id=\"T_81439_row3_col1\" class=\"data row3 col1\" >133.08</td>\n",
              "      <td id=\"T_81439_row3_col2\" class=\"data row3 col2\" >211609.92</td>\n",
              "      <td id=\"T_81439_row3_col3\" class=\"data row3 col3\" >460.01</td>\n",
              "      <td id=\"T_81439_row3_col4\" class=\"data row3 col4\" >-91.56</td>\n",
              "      <td id=\"T_81439_row3_col5\" class=\"data row3 col5\" >-326.96</td>\n",
              "      <td id=\"T_81439_row3_col6\" class=\"data row3 col6\" >-152597.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Target 3 : TotalDamageAdjusted(000US$)**"
      ],
      "metadata": {
        "id": "jj0f8LzHH8uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "LINEAR_TARGETS = [\"TotalDeaths\", \"NoInjured\", \"TotalDamageAdjusted(000US$)\"]\n",
        "ATTRIBUTES = ['Year', 'Month', 'MainLandfallLocation', 'OFDAResponse', 'Appeal', 'Declaration', 'LandfallMagnitude(kph)', 'LandfallPressure(mb)']\n",
        "CATEGORICAL_TARGETS = ['Flood', 'Slide']\n",
        "\n",
        "X = df[ATTRIBUTES + CATEGORICAL_TARGETS]\n",
        "y = df[LINEAR_TARGETS[2]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2URG3A9BIDNv"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TabNet**"
      ],
      "metadata": {
        "id": "4Z31iX3jz0Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Convert data to NumPy arrays (if they are not already)\n",
        "X_train_np = X_train_scaled\n",
        "X_test_np = X_test_scaled\n",
        "y_train_np = y_train.values.reshape(-1, 1)\n",
        "y_test_np = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Define the TabNet Regressor\n",
        "tabnet_model = TabNetRegressor()\n",
        "\n",
        "# Train the model with verbose set to 0\n",
        "tabnet_model.fit(\n",
        "    X_train_np, y_train_np,\n",
        "    eval_set=[(X_test_np, y_test_np)],\n",
        "    eval_metric=['rmse'],\n",
        "    max_epochs=100,\n",
        "    patience=100,\n",
        "    batch_size=32,\n",
        "    virtual_batch_size=8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBp4rhG-IIWw",
        "outputId": "d4fbc1cd-c6e6-4eb3-9704-1bcfa99dbaf4"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 59933203456.0| val_0_rmse: 286303.09674|  0:00:00s\n",
            "epoch 1  | loss: 56422007808.0| val_0_rmse: 286302.05232|  0:00:00s\n",
            "epoch 2  | loss: 57089082368.0| val_0_rmse: 286300.35414|  0:00:00s\n",
            "epoch 3  | loss: 52097675008.0| val_0_rmse: 286299.0372|  0:00:01s\n",
            "epoch 4  | loss: 55271347200.0| val_0_rmse: 286297.78731|  0:00:01s\n",
            "epoch 5  | loss: 58143604736.0| val_0_rmse: 286291.09494|  0:00:01s\n",
            "epoch 6  | loss: 57428844032.0| val_0_rmse: 286291.52883|  0:00:01s\n",
            "epoch 7  | loss: 56114516096.0| val_0_rmse: 286286.36255|  0:00:01s\n",
            "epoch 8  | loss: 59089842688.0| val_0_rmse: 286285.31364|  0:00:01s\n",
            "epoch 9  | loss: 50765489152.0| val_0_rmse: 286284.26121|  0:00:02s\n",
            "epoch 10 | loss: 53528266752.0| val_0_rmse: 286281.04692|  0:00:02s\n",
            "epoch 11 | loss: 42522254336.0| val_0_rmse: 286279.59562|  0:00:02s\n",
            "epoch 12 | loss: 55818397696.0| val_0_rmse: 286272.00518|  0:00:02s\n",
            "epoch 13 | loss: 45203825152.0| val_0_rmse: 286275.65147|  0:00:02s\n",
            "epoch 14 | loss: 59033167872.0| val_0_rmse: 286270.52226|  0:00:03s\n",
            "epoch 15 | loss: 49800992000.0| val_0_rmse: 286264.3772|  0:00:03s\n",
            "epoch 16 | loss: 59477798912.0| val_0_rmse: 286257.97934|  0:00:03s\n",
            "epoch 17 | loss: 56018249472.0| val_0_rmse: 286261.41729|  0:00:03s\n",
            "epoch 18 | loss: 47339379200.0| val_0_rmse: 286257.37504|  0:00:03s\n",
            "epoch 19 | loss: 58687483904.0| val_0_rmse: 286249.05206|  0:00:03s\n",
            "epoch 20 | loss: 42537484288.0| val_0_rmse: 286240.57456|  0:00:03s\n",
            "epoch 21 | loss: 54745705472.0| val_0_rmse: 286229.58734|  0:00:04s\n",
            "epoch 22 | loss: 50368333056.0| val_0_rmse: 286217.50969|  0:00:04s\n",
            "epoch 23 | loss: 51862809088.0| val_0_rmse: 286206.74994|  0:00:04s\n",
            "epoch 24 | loss: 57109496064.0| val_0_rmse: 286196.41236|  0:00:04s\n",
            "epoch 25 | loss: 59204558848.0| val_0_rmse: 286186.71932|  0:00:04s\n",
            "epoch 26 | loss: 58322462208.0| val_0_rmse: 286180.40872|  0:00:04s\n",
            "epoch 27 | loss: 53298220032.0| val_0_rmse: 286174.25275|  0:00:04s\n",
            "epoch 28 | loss: 51169654784.0| val_0_rmse: 286174.04602|  0:00:05s\n",
            "epoch 29 | loss: 49973470208.0| val_0_rmse: 286166.03586|  0:00:05s\n",
            "epoch 30 | loss: 49951335424.0| val_0_rmse: 286151.30166|  0:00:05s\n",
            "epoch 31 | loss: 47766943744.0| val_0_rmse: 286146.17045|  0:00:05s\n",
            "epoch 32 | loss: 59657335808.0| val_0_rmse: 286136.97308|  0:00:05s\n",
            "epoch 33 | loss: 56712796160.0| val_0_rmse: 286127.23657|  0:00:05s\n",
            "epoch 34 | loss: 56876474368.0| val_0_rmse: 286113.86288|  0:00:06s\n",
            "epoch 35 | loss: 56361421824.0| val_0_rmse: 286107.42281|  0:00:06s\n",
            "epoch 36 | loss: 59161103872.0| val_0_rmse: 286106.58931|  0:00:06s\n",
            "epoch 37 | loss: 51809965568.0| val_0_rmse: 286110.65087|  0:00:06s\n",
            "epoch 38 | loss: 46987402240.0| val_0_rmse: 286110.63533|  0:00:06s\n",
            "epoch 39 | loss: 53102781696.0| val_0_rmse: 286088.33966|  0:00:06s\n",
            "epoch 40 | loss: 57889378304.0| val_0_rmse: 286079.35317|  0:00:06s\n",
            "epoch 41 | loss: 50565250304.0| val_0_rmse: 286060.73618|  0:00:07s\n",
            "epoch 42 | loss: 55395911680.0| val_0_rmse: 286053.46112|  0:00:07s\n",
            "epoch 43 | loss: 49149004416.0| val_0_rmse: 286046.65438|  0:00:07s\n",
            "epoch 44 | loss: 40536299008.0| val_0_rmse: 286045.51459|  0:00:07s\n",
            "epoch 45 | loss: 52186488320.0| val_0_rmse: 286029.55528|  0:00:07s\n",
            "epoch 46 | loss: 41131843072.0| val_0_rmse: 286008.6652|  0:00:07s\n",
            "epoch 47 | loss: 39158766592.0| val_0_rmse: 285974.3904|  0:00:08s\n",
            "epoch 48 | loss: 45869431808.0| val_0_rmse: 285933.60691|  0:00:08s\n",
            "epoch 49 | loss: 55122958848.0| val_0_rmse: 285889.83177|  0:00:08s\n",
            "epoch 50 | loss: 40394270208.0| val_0_rmse: 285878.67206|  0:00:08s\n",
            "epoch 51 | loss: 48282547712.0| val_0_rmse: 285809.71049|  0:00:08s\n",
            "epoch 52 | loss: 53902324736.0| val_0_rmse: 285795.23933|  0:00:08s\n",
            "epoch 53 | loss: 48778647040.0| val_0_rmse: 285832.42063|  0:00:09s\n",
            "epoch 54 | loss: 52932390400.0| val_0_rmse: 285847.33243|  0:00:09s\n",
            "epoch 55 | loss: 58581219328.0| val_0_rmse: 285849.95188|  0:00:09s\n",
            "epoch 56 | loss: 54041798656.0| val_0_rmse: 285836.64216|  0:00:09s\n",
            "epoch 57 | loss: 56587938816.0| val_0_rmse: 285822.97203|  0:00:09s\n",
            "epoch 58 | loss: 48122892288.0| val_0_rmse: 285790.36995|  0:00:09s\n",
            "epoch 59 | loss: 49016206336.0| val_0_rmse: 285790.2552|  0:00:09s\n",
            "epoch 60 | loss: 55738056192.0| val_0_rmse: 285785.12087|  0:00:10s\n",
            "epoch 61 | loss: 48631056128.0| val_0_rmse: 285788.5467|  0:00:10s\n",
            "epoch 62 | loss: 57421002752.0| val_0_rmse: 285765.51095|  0:00:10s\n",
            "epoch 63 | loss: 43446507008.0| val_0_rmse: 285739.43108|  0:00:10s\n",
            "epoch 64 | loss: 51790950400.0| val_0_rmse: 285707.43323|  0:00:10s\n",
            "epoch 65 | loss: 47397642752.0| val_0_rmse: 285679.32191|  0:00:11s\n",
            "epoch 66 | loss: 49590296064.0| val_0_rmse: 285633.25579|  0:00:11s\n",
            "epoch 67 | loss: 56813409792.0| val_0_rmse: 285620.77226|  0:00:11s\n",
            "epoch 68 | loss: 57224044032.0| val_0_rmse: 285606.00504|  0:00:11s\n",
            "epoch 69 | loss: 48314687744.0| val_0_rmse: 285601.5331|  0:00:11s\n",
            "epoch 70 | loss: 51449346048.0| val_0_rmse: 285605.2798|  0:00:12s\n",
            "epoch 71 | loss: 52788368384.0| val_0_rmse: 285619.20276|  0:00:12s\n",
            "epoch 72 | loss: 55928195072.0| val_0_rmse: 285601.11332|  0:00:12s\n",
            "epoch 73 | loss: 48741827584.0| val_0_rmse: 285555.59443|  0:00:12s\n",
            "epoch 74 | loss: 59716908288.0| val_0_rmse: 285503.9883|  0:00:12s\n",
            "epoch 75 | loss: 54164032000.0| val_0_rmse: 285422.91163|  0:00:13s\n",
            "epoch 76 | loss: 56762526208.0| val_0_rmse: 285403.39888|  0:00:13s\n",
            "epoch 77 | loss: 57249800192.0| val_0_rmse: 285356.14742|  0:00:13s\n",
            "epoch 78 | loss: 56741060096.0| val_0_rmse: 285332.36731|  0:00:13s\n",
            "epoch 79 | loss: 52749892608.0| val_0_rmse: 285309.42246|  0:00:14s\n",
            "epoch 80 | loss: 46511384832.0| val_0_rmse: 285265.39312|  0:00:14s\n",
            "epoch 81 | loss: 57895317504.0| val_0_rmse: 285230.39773|  0:00:14s\n",
            "epoch 82 | loss: 59583354880.0| val_0_rmse: 285238.40209|  0:00:14s\n",
            "epoch 83 | loss: 51560235776.0| val_0_rmse: 285211.96815|  0:00:14s\n",
            "epoch 84 | loss: 52016581632.0| val_0_rmse: 285210.51724|  0:00:14s\n",
            "epoch 85 | loss: 51417445632.0| val_0_rmse: 285171.12087|  0:00:15s\n",
            "epoch 86 | loss: 56298183936.0| val_0_rmse: 285137.08563|  0:00:15s\n",
            "epoch 87 | loss: 48549826560.0| val_0_rmse: 284889.14634|  0:00:15s\n",
            "epoch 88 | loss: 54948328192.0| val_0_rmse: 284670.9307|  0:00:15s\n",
            "epoch 89 | loss: 55660251136.0| val_0_rmse: 284680.75968|  0:00:15s\n",
            "epoch 90 | loss: 60083310592.0| val_0_rmse: 284650.62882|  0:00:15s\n",
            "epoch 91 | loss: 57678580864.0| val_0_rmse: 284668.93671|  0:00:15s\n",
            "epoch 92 | loss: 56159450624.0| val_0_rmse: 284660.21285|  0:00:16s\n",
            "epoch 93 | loss: 34331591680.0| val_0_rmse: 284668.7684|  0:00:16s\n",
            "epoch 94 | loss: 53957423616.0| val_0_rmse: 284679.66022|  0:00:16s\n",
            "epoch 95 | loss: 45746909696.0| val_0_rmse: 284977.0661|  0:00:16s\n",
            "epoch 96 | loss: 48127568384.0| val_0_rmse: 285321.05637|  0:00:16s\n",
            "epoch 97 | loss: 60436346368.0| val_0_rmse: 285315.597|  0:00:16s\n",
            "epoch 98 | loss: 53724691456.0| val_0_rmse: 285307.69461|  0:00:16s\n",
            "epoch 99 | loss: 51690634240.0| val_0_rmse: 285028.4994|  0:00:17s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_rmse = 284650.62882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(tabnet_model, X_test_np, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict = {}\n",
        "evaluate_dict[\"TabNet\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90_YoFpRIWf5",
        "outputId": "2f407c15-b592-40ef-a7fc-f2f3dcde0a96"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 122286.02,\n",
              " 'mse': 81025980486.77,\n",
              " 'rmse': 284650.63,\n",
              " 'mae_upperbound_tolerance': -85179.62,\n",
              " 'rmse_upperbound_tolerance': -207188.13,\n",
              " 'mse_upperbound_tolerance': -61024519290.22}"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**"
      ],
      "metadata": {
        "id": "PN-t3sLTz2_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, units):\n",
        "    shortcut = x\n",
        "    x = layers.Dense(units, activation='relu')(x)\n",
        "    x = layers.Dense(units)(x)  # No activation for the second layer\n",
        "    x = layers.add([x, shortcut])  # Add the shortcut\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_resnet(input_shape, output_units):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "    # Add several residual blocks\n",
        "    for _ in range(3):  # Adjust the number of blocks as needed\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    outputs = layers.Dense(output_units)(x)  # For regression, no activation here\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "resnet_model = build_resnet(input_shape=(X_train_scaled.shape[1],), output_units=1)\n",
        "resnet_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
        "\n",
        "resnet_model.fit(X_train_scaled, y_train_np, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_np), callbacks=[checkpoint], verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzb7bu_Nz6CD",
        "outputId": "1219a11e-d901-456c-846d-5aeaca20ebe0"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972f84cb460>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(resnet_model, X_test_scaled, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"ResNet\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV-ur7Y50EHz",
        "outputId": "a7e803ce-9d68-44b4-f54f-058a0c4b9cff"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 101821.06,\n",
              " 'mse': 28939500423.19,\n",
              " 'rmse': 170116.14,\n",
              " 'mae_upperbound_tolerance': -64714.66,\n",
              " 'rmse_upperbound_tolerance': -92653.64,\n",
              " 'mse_upperbound_tolerance': -8938039226.63}"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wide & Deep Model**"
      ],
      "metadata": {
        "id": "o_WMU0I10KfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "# Wide part (linear connection)\n",
        "wide_layer = Dense(1, activation='linear')(input_layer)\n",
        "\n",
        "# Deep part\n",
        "deep_layer = Dense(128, activation='relu')(input_layer)\n",
        "deep_layer = Dense(64, activation='relu')(deep_layer)\n",
        "deep_layer = Dense(32, activation='relu')(deep_layer)\n",
        "\n",
        "# Combine Wide and Deep parts\n",
        "combined = concatenate([wide_layer, deep_layer])\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation='linear')(combined)\n",
        "\n",
        "# Build and compile the model\n",
        "deep_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "deep_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "deep_model.fit(X_train_scaled, y_train_np, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_np), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWGe270q0Nus",
        "outputId": "c85d68c0-996b-4575-d0a2-1965ad6e1302"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79730eb5ff70>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(deep_model, X_test_scaled, y_test_np, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"Wide & Deep Model\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDZ0E2230XKW",
        "outputId": "1bd30d16-df13-4c66-8559-9a5e27fbc175"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 105283.89,\n",
              " 'mse': 40908552925.02,\n",
              " 'rmse': 202258.63,\n",
              " 'mae_upperbound_tolerance': -68177.49,\n",
              " 'rmse_upperbound_tolerance': -124796.13,\n",
              " 'mse_upperbound_tolerance': -20907091728.47}"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "NUkz7qc00cAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for LSTM\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y.iloc[i + time_steps])  # Corresponding y value\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "TIME_STEPS = 1  # You can change this value based on your needs\n",
        "X_train_lstm, y_train_lstm = create_dataset(pd.DataFrame(X_train_scaled), pd.Series(y_train), TIME_STEPS)\n",
        "X_test_lstm, y_test_lstm = create_dataset(pd.DataFrame(X_test_scaled), pd.Series(y_test), TIME_STEPS)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
        "X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2]))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))  # Output layer for regression (adjust this based on the number of targets)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_lstm, y_train_lstm, epochs=100, batch_size=32, validation_data=(X_test_lstm, y_test_lstm), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCDkn4of0dk0",
        "outputId": "6bb1e433-300d-4084-e58f-6ea2d56d8e38"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79730e8b9030>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_values = evaluate(model, X_test_lstm, y_test_lstm, threshold=0.3, mode=\"regression\")\n",
        "evaluate_dict[\"LSTM\"] = eval_values\n",
        "\n",
        "eval_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87GTF3Wp0mIz",
        "outputId": "e09dea23-8e0e-4712-fdc0-333b5381e1f7"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 125518.38,\n",
              " 'mse': 84150972646.34,\n",
              " 'rmse': 290087.87,\n",
              " 'mae_upperbound_tolerance': -87856.27,\n",
              " 'rmse_upperbound_tolerance': -211629.66,\n",
              " 'mse_upperbound_tolerance': -63632002088.16}"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare metrics value\n",
        "def highlight_max(s):\n",
        "    is_max = s == s.max()\n",
        "    return ['color: red' if v else '' for v in is_max]\n",
        "\n",
        "def highlight_min(s):\n",
        "    is_min = s == s.min()\n",
        "    return ['color: red' if v else '' for v in is_min]\n",
        "\n",
        "def highlight_row(row, selected_method):\n",
        "    return ['background-color: black;' if row['Method'] in selected_method else ''\n",
        "            for _ in row]\n",
        "\n",
        "selected_method = [model.__class__.__name__]\n",
        "eval_value_df = pd.DataFrame(evaluate_dict).T.reset_index().rename(columns={\"index\":\"Method\"})\n",
        "\n",
        "eval_value_df = (\n",
        "    eval_value_df.style\n",
        "    .apply(highlight_max, subset=[\"mae_upperbound_tolerance\", \"rmse_upperbound_tolerance\", \"mse_upperbound_tolerance\"])\n",
        "    .apply(highlight_min, subset=[\"mae\", \"mse\", \"rmse\"])\n",
        "    .apply(lambda row: highlight_row(row, selected_method), axis=1 )\n",
        "    .format(precision=2)\n",
        ")\n",
        "\n",
        "eval_value_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "kfyHYmdP0sUr",
        "outputId": "843ee88f-94fa-4d58-c242-56d1f86fcc7d"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7972f84cabc0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b67f6_row1_col1, #T_b67f6_row1_col2, #T_b67f6_row1_col3, #T_b67f6_row1_col4, #T_b67f6_row1_col5, #T_b67f6_row1_col6 {\n",
              "  color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b67f6\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_b67f6_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
              "      <th id=\"T_b67f6_level0_col1\" class=\"col_heading level0 col1\" >mae</th>\n",
              "      <th id=\"T_b67f6_level0_col2\" class=\"col_heading level0 col2\" >mse</th>\n",
              "      <th id=\"T_b67f6_level0_col3\" class=\"col_heading level0 col3\" >rmse</th>\n",
              "      <th id=\"T_b67f6_level0_col4\" class=\"col_heading level0 col4\" >mae_upperbound_tolerance</th>\n",
              "      <th id=\"T_b67f6_level0_col5\" class=\"col_heading level0 col5\" >rmse_upperbound_tolerance</th>\n",
              "      <th id=\"T_b67f6_level0_col6\" class=\"col_heading level0 col6\" >mse_upperbound_tolerance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_b67f6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_b67f6_row0_col0\" class=\"data row0 col0\" >TabNet</td>\n",
              "      <td id=\"T_b67f6_row0_col1\" class=\"data row0 col1\" >122286.02</td>\n",
              "      <td id=\"T_b67f6_row0_col2\" class=\"data row0 col2\" >81025980486.77</td>\n",
              "      <td id=\"T_b67f6_row0_col3\" class=\"data row0 col3\" >284650.63</td>\n",
              "      <td id=\"T_b67f6_row0_col4\" class=\"data row0 col4\" >-85179.62</td>\n",
              "      <td id=\"T_b67f6_row0_col5\" class=\"data row0 col5\" >-207188.13</td>\n",
              "      <td id=\"T_b67f6_row0_col6\" class=\"data row0 col6\" >-61024519290.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b67f6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_b67f6_row1_col0\" class=\"data row1 col0\" >ResNet</td>\n",
              "      <td id=\"T_b67f6_row1_col1\" class=\"data row1 col1\" >101821.06</td>\n",
              "      <td id=\"T_b67f6_row1_col2\" class=\"data row1 col2\" >28939500423.19</td>\n",
              "      <td id=\"T_b67f6_row1_col3\" class=\"data row1 col3\" >170116.14</td>\n",
              "      <td id=\"T_b67f6_row1_col4\" class=\"data row1 col4\" >-64714.66</td>\n",
              "      <td id=\"T_b67f6_row1_col5\" class=\"data row1 col5\" >-92653.64</td>\n",
              "      <td id=\"T_b67f6_row1_col6\" class=\"data row1 col6\" >-8938039226.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b67f6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_b67f6_row2_col0\" class=\"data row2 col0\" >Wide & Deep Model</td>\n",
              "      <td id=\"T_b67f6_row2_col1\" class=\"data row2 col1\" >105283.89</td>\n",
              "      <td id=\"T_b67f6_row2_col2\" class=\"data row2 col2\" >40908552925.02</td>\n",
              "      <td id=\"T_b67f6_row2_col3\" class=\"data row2 col3\" >202258.63</td>\n",
              "      <td id=\"T_b67f6_row2_col4\" class=\"data row2 col4\" >-68177.49</td>\n",
              "      <td id=\"T_b67f6_row2_col5\" class=\"data row2 col5\" >-124796.13</td>\n",
              "      <td id=\"T_b67f6_row2_col6\" class=\"data row2 col6\" >-20907091728.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b67f6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_b67f6_row3_col0\" class=\"data row3 col0\" >LSTM</td>\n",
              "      <td id=\"T_b67f6_row3_col1\" class=\"data row3 col1\" >125518.38</td>\n",
              "      <td id=\"T_b67f6_row3_col2\" class=\"data row3 col2\" >84150972646.34</td>\n",
              "      <td id=\"T_b67f6_row3_col3\" class=\"data row3 col3\" >290087.87</td>\n",
              "      <td id=\"T_b67f6_row3_col4\" class=\"data row3 col4\" >-87856.27</td>\n",
              "      <td id=\"T_b67f6_row3_col5\" class=\"data row3 col5\" >-211629.66</td>\n",
              "      <td id=\"T_b67f6_row3_col6\" class=\"data row3 col6\" >-63632002088.16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet hoạt động tốt với target 1, Wide & Deep Model\ttốt trên target 2, trong khi ResNet có kết quả tốt nhất trên target 3"
      ],
      "metadata": {
        "id": "f2Fezxju1LBT"
      }
    }
  ]
}