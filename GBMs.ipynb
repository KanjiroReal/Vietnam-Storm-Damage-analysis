{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GIQSefYEcpdV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "d:\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>EventName</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>DisasterType</th>\n",
              "      <th>DisasterSubtype</th>\n",
              "      <th>MainLandfallLocation</th>\n",
              "      <th>Flood</th>\n",
              "      <th>Slide</th>\n",
              "      <th>OFDAResponse</th>\n",
              "      <th>Appeal</th>\n",
              "      <th>Declaration</th>\n",
              "      <th>LandfallMagnitude(kph)</th>\n",
              "      <th>LandfallPressure(mb)</th>\n",
              "      <th>TotalDeaths</th>\n",
              "      <th>NoInjured</th>\n",
              "      <th>TotalDamage(000US$)</th>\n",
              "      <th>TotalDamageAdjusted(000US$)</th>\n",
              "      <th>CPI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>STORM_NAN_1953</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1953</td>\n",
              "      <td>9</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "      <td>989</td>\n",
              "      <td>1000</td>\n",
              "      <td>20</td>\n",
              "      <td>19400</td>\n",
              "      <td>211880</td>\n",
              "      <td>9.156133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>STORM_VIOLET_1964</td>\n",
              "      <td>Violet</td>\n",
              "      <td>1964</td>\n",
              "      <td>9</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "      <td>989</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>10000</td>\n",
              "      <td>94354</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STORM_IRIS_1964</td>\n",
              "      <td>Iris</td>\n",
              "      <td>1964</td>\n",
              "      <td>11</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>960</td>\n",
              "      <td>5100</td>\n",
              "      <td>20</td>\n",
              "      <td>70000</td>\n",
              "      <td>660479</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>STORM_JOAN_1964</td>\n",
              "      <td>Joan</td>\n",
              "      <td>1964</td>\n",
              "      <td>11</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>980</td>\n",
              "      <td>2500</td>\n",
              "      <td>20</td>\n",
              "      <td>15000</td>\n",
              "      <td>141531</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STORM_KATE_1964</td>\n",
              "      <td>Kate</td>\n",
              "      <td>1964</td>\n",
              "      <td>11</td>\n",
              "      <td>Storm</td>\n",
              "      <td>Tropical cyclone</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>970</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>3000</td>\n",
              "      <td>28306</td>\n",
              "      <td>10.598376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ID EventName  Year  Month DisasterType   DisasterSubtype  \\\n",
              "0     STORM_NAN_1953       NaN  1953      9        Storm  Tropical cyclone   \n",
              "1  STORM_VIOLET_1964   Violet   1964      9        Storm  Tropical cyclone   \n",
              "2    STORM_IRIS_1964      Iris  1964     11        Storm  Tropical cyclone   \n",
              "3    STORM_JOAN_1964      Joan  1964     11        Storm  Tropical cyclone   \n",
              "4    STORM_KATE_1964      Kate  1964     11        Storm  Tropical cyclone   \n",
              "\n",
              "   MainLandfallLocation  Flood  Slide  OFDAResponse  Appeal  Declaration  \\\n",
              "0                     8      0      0             0       0            0   \n",
              "1                     4      1      1             0       0            0   \n",
              "2                     5      1      0             0       0            0   \n",
              "3                     5      1      0             0       0            0   \n",
              "4                     6      1      0             0       0            0   \n",
              "\n",
              "   LandfallMagnitude(kph)  LandfallPressure(mb)  TotalDeaths  NoInjured  \\\n",
              "0                      92                   989         1000         20   \n",
              "1                      92                   989           18         20   \n",
              "2                     150                   960         5100         20   \n",
              "3                     130                   980         2500         20   \n",
              "4                     130                   970            0         20   \n",
              "\n",
              "   TotalDamage(000US$)  TotalDamageAdjusted(000US$)        CPI  \n",
              "0                19400                       211880   9.156133  \n",
              "1                10000                        94354  10.598376  \n",
              "2                70000                       660479  10.598376  \n",
              "3                15000                       141531  10.598376  \n",
              "4                 3000                        28306  10.598376  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.const import DATA_HEAD, WEIGHTS_HEAD\n",
        "ML_dir = WEIGHTS_HEAD / \"ML\"\n",
        "\n",
        "data_filename = DATA_HEAD / \"STORM_preprocessed_medianfill_1.csv\"\n",
        "base_df = pd.read_csv(str(data_filename), index_col=0)\n",
        "base_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_df['MainLandfallLocation'] = base_df['MainLandfallLocation'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RDQhwM6XAMm"
      },
      "source": [
        "# Featue importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCOQG6_mLKtM"
      },
      "source": [
        "target: death, injure, total dmg adjust . metric: mse, terminate the large error in predict dmg, phu hop voi gbms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "| **Mô hình**               | **Ưu điểm**                            | **Nhược điểm**                          | **Khi nào dùng?**                       |\n",
        "|---------------------------|----------------------------------------|-----------------------------------------|----------------------------------------|\n",
        "| XGBoost                   | Hiệu quả cao, chống overfitting        | Tốn tài nguyên, huấn luyện chậm         | Dữ liệu lớn, nhiều tính năng                   |\n",
        "| LightGBM                  | Nhanh, hiệu quả trên dữ liệu lớn       | Thiếu chính xác với dữ liệu nhỏ         | Dữ liệu lớn, cần tốc độ        |\n",
        "| CatBoost                  | Tốt cho dữ liệu phân loại              | Cần nhiều tài nguyên                    | Khi có nhiều tính năng phân loại                       |\n",
        "| AdaBoost                  | Đơn giản, dễ triển khai                | Hiệu suất kém hơn các GBM khác          | Dữ liệu nhỏ, ít biến động                       |\n",
        "| Decision Trees (GBDT)     | Dự đoán chính xác với dữ liệu phi tuyến| Chậm khi số lượng cây lớn               | Dữ liệu phi tuyến, phức tạp                     |\n",
        "| NGBoost                   | Mô hình hóa phân phối xác suất         | Phức tạp hơn, ít phổ biến               | Khi cần dự đoán phân phối xác suất                   |\n",
        "\n",
        "**Model selection**\n",
        "1. `XGBoost`\n",
        "   - XGBoost is highly effective for data that contains both linear and non-linear relationships. \n",
        "   - It is suitable for datasets with many features, where overfitting might be a concern. XGBoost provides robust feature importance, making it ideal for understanding key factors in complex datasets.\n",
        "2. `LightGBM`\n",
        "   - LightGBM is a fast and efficient model that is particularly effective on datasets with a large number of features. \n",
        "   - It is suitable when quick training is required without sacrificing performance, making it a strong option when speed is prioritized and feature importance needs to be calculated quickly.\n",
        "3. `CatBoost`\n",
        "   - CatBoost is designed to handle datasets with many categorical variables without the need for extensive preprocessing, such as one-hot encoding. \n",
        "   - It is particularly useful when working with datasets that contain mixed feature types (numerical and categorical) and when minimal data preprocessing is desired, while still delivering accurate feature importance.\n",
        "4. `Decision Trees (GBDT)`\n",
        "   - Decision Trees (GBDT) are effective at capturing complex, non-linear patterns in data.\n",
        "   - It is suitable for datasets with non-linear relationships and complex interactions between features, especially when the goal is to model accurate predictions while identifying the most important features contributing to those predictions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv0NTkBsQhtO"
      },
      "source": [
        "## One hot encoding ( Not use yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_label = ['North_East', 'North_West', 'Red_River_Delta', 'North_Central_Coast', 'South_Central_Coast', 'Central_Highlands', 'South_East', 'Mekong_River_Delta']\n",
        "map_dict = {i: name for i, name in enumerate(x_label, start=1)}\n",
        "\n",
        "base_df['MainLandfallLocation'] = base_df['MainLandfallLocation'].map(map_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ4ggyCcRMxf"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDICT LINEAR_TARGET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "__kNkF94R6C8"
      },
      "outputs": [],
      "source": [
        "from src.const import LINEAR_TARGETS, ATTRIBUTES, CATEGORICAL_TARGETS \n",
        "\n",
        "predictors = ATTRIBUTES + CATEGORICAL_TARGETS \n",
        "\n",
        "# Exclude highly correlated variables like TotalDamage and focus on TotalDamageAdjusted\n",
        "target = LINEAR_TARGETS\n",
        "\n",
        "X = base_df[predictors]\n",
        "y = base_df[target]\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lvkdr8RGSA22"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "xgb_model = XGBRegressor(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjJBmznQOaMe",
        "outputId": "56613f5b-379d-4ef3-fb21-4323829fd432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2196904077.038385,\n",
              " 12995833700.612913,\n",
              " {'colsample_bytree': 0.8,\n",
              "  'gamma': 0.1,\n",
              "  'learning_rate': 0.05,\n",
              "  'max_depth': 3,\n",
              "  'min_child_weight': 3,\n",
              "  'n_estimators': 200,\n",
              "  'reg_alpha': 0.1,\n",
              "  'reg_lambda': 2,\n",
              "  'subsample': 0.7},\n",
              "                   Feature  Importance\n",
              " 4                  Appeal    0.199368\n",
              " 6  LandfallMagnitude(kph)    0.143474\n",
              " 9                   Slide    0.131806\n",
              " 0                    Year    0.115112\n",
              " 2    MainLandfallLocation    0.099156\n",
              " 3            OFDAResponse    0.094092\n",
              " 7    LandfallPressure(mb)    0.092087\n",
              " 1                   Month    0.080761\n",
              " 8                   Flood    0.044143\n",
              " 5             Declaration    0.000000)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Increase number of trees\n",
        "    'learning_rate': [0.01, 0.05, 0.1],  # Try smaller learning rates for smoother learning\n",
        "    'max_depth': [3, 5, 7],  # Test deeper trees for better performance with complex relationships\n",
        "    'subsample': [0.7, 0.8, 1.0],  # Introduce randomness to reduce overfitting\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],  # Randomly sample columns to increase model robustness\n",
        "    'min_child_weight': [1, 3, 5],  # Prevent splitting with too few samples\n",
        "    'gamma': [0, 0.1, 0.3],  # Regularization to reduce overly complex trees\n",
        "    'reg_alpha': [0, 0.1, 0.5],  # L1 regularization for feature selection\n",
        "    'reg_lambda': [1, 1.5, 2]  # L2 regularization to prevent overfitting\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Set up cross-validation with grid search\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "\n",
        "# Step 4: Train the model using cross-validation to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Use the best found model to make predictions\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the model using MSE for both training and testing sets\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "# Step 7: Analyze feature importance from the best model\n",
        "feature_importance = best_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importance alongside their names\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Output the results: MSE and feature importance\n",
        "mse_train, mse_test, grid_search.best_params_, importance_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDICT CATEGORICAL_TARGETS "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.const import ATTRIBUTES, CATEGORICAL_TARGETS \n",
        "\n",
        "predictors = ATTRIBUTES \n",
        "\n",
        "# Exclude highly correlated variables like TotalDamage and focus on TotalDamageAdjusted\n",
        "target = CATEGORICAL_TARGETS\n",
        "\n",
        "X = base_df[predictors]\n",
        "y = base_df[target]\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 19683 candidates, totalling 59049 fits\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Increase number of trees\n",
        "    'learning_rate': [0.01, 0.05, 0.1],  # Try smaller learning rates for smoother learning\n",
        "    'max_depth': [3, 5, 7],  # Test deeper trees for better performance with complex relationships\n",
        "    'subsample': [0.7, 0.8, 1.0],  # Introduce randomness to reduce overfitting\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],  # Randomly sample columns to increase model robustness\n",
        "    'min_child_weight': [1, 3, 5],  # Prevent splitting with too few samples\n",
        "    'gamma': [0, 0.1, 0.3],  # Regularization to reduce overly complex trees\n",
        "    'reg_alpha': [0, 0.1, 0.5],  # L1 regularization for feature selection\n",
        "    'reg_lambda': [1, 1.5, 2]  # L2 regularization to prevent overfitting\n",
        "}\n",
        "\n",
        "\n",
        "# Set up cross-validation with grid search\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "\n",
        "# Step 4: Train the model using cross-validation to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Use the best found model to make predictions\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the model using MSE for both training and testing sets\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "# Step 7: Analyze feature importance from the best model\n",
        "feature_importance = best_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importance alongside their names\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Output the results: MSE and feature importance\n",
        "mse_train, mse_test, grid_search.best_params_, importance_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts9ZnKn3T3hz"
      },
      "source": [
        "## LightGBM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_lgb = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [15, 31, 50],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'feature_fraction': [0.6, 0.8, 1.0],\n",
        "    'bagging_fraction': [0.6, 0.8, 1.0],\n",
        "    'bagging_freq': [3, 5, 10]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDITC LINEAR_TARGET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'pandas.core.strings' has no attribute 'StringMethods'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"LightGBM, Light Gradient Boosting Machine.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/microsoft/LightGBM/graphs/contributors.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     PANDAS_INSTALLED,\n\u001b[0;32m     24\u001b[0m     PYARROW_INSTALLED,\n\u001b[0;32m     25\u001b[0m     arrow_cffi,\n\u001b[0;32m     26\u001b[0m     arrow_is_boolean,\n\u001b[0;32m     27\u001b[0m     arrow_is_floating,\n\u001b[0;32m     28\u001b[0m     arrow_is_integer,\n\u001b[0;32m     29\u001b[0m     concat,\n\u001b[0;32m     30\u001b[0m     dt_DataTable,\n\u001b[0;32m     31\u001b[0m     pa_Array,\n\u001b[0;32m     32\u001b[0m     pa_chunked_array,\n\u001b[0;32m     33\u001b[0m     pa_ChunkedArray,\n\u001b[0;32m     34\u001b[0m     pa_compute,\n\u001b[0;32m     35\u001b[0m     pa_Table,\n\u001b[0;32m     36\u001b[0m     pd_CategoricalDtype,\n\u001b[0;32m     37\u001b[0m     pd_DataFrame,\n\u001b[0;32m     38\u001b[0m     pd_Series,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_lib_path\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\compat.py:152\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_delayed \u001b[38;5;28;01mas\u001b[39;00m dask_array_from_delayed\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_delayed \u001b[38;5;28;01mas\u001b[39;00m dask_bag_from_delayed\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame \u001b[38;5;28;01mas\u001b[39;00m dask_DataFrame\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series \u001b[38;5;28;01mas\u001b[39;00m dask_Series\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client, Future, default_client, wait\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, dispatch, rolling\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m         DataFrame,\n\u001b[0;32m      6\u001b[0m         Index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m         to_timedelta,\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Aggregation\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\backends.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msizeof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleSizeof, sizeof\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_arraylike, typename\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame, Index, Scalar, Series, _Frame\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     categorical_dtype_dispatch,\n\u001b[0;32m     26\u001b[0m     concat,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     union_categoricals_dispatch,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_array_nonempty, make_scalar\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:52\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m methods\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PANDAS_GT_140, PANDAS_GT_150\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatetimeAccessor, StringAccessor\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalAccessor, categorize\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     55\u001b[0m     get_parallel_type,\n\u001b[0;32m     56\u001b[0m     group_split_dispatch,\n\u001b[0;32m     57\u001b[0m     hash_object_dispatch,\n\u001b[0;32m     58\u001b[0m     meta_nonempty,\n\u001b[0;32m     59\u001b[0m )\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\accessor.py:112\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124;03m\"\"\"Accessor object for datetimelike properties of the Series values.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    >>> s.dt.microsecond  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStringAccessor\u001b[39;00m(Accessor):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;124;03m\"\"\"Accessor object for string properties of the Series values.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    >>> s.str.lower()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\accessor.py:124\u001b[0m, in \u001b[0;36mStringAccessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m _not_implemented \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_dummies\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;129m@derived_from\u001b[39m(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringMethods\u001b[49m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, pat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expand:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.core.strings' has no attribute 'StringMethods'"
          ]
        }
      ],
      "source": [
        "from src.const import LINEAR_TARGETS, ATTRIBUTES\n",
        "\n",
        "predictors = ATTRIBUTES + LINEAR_TARGETS\n",
        "\n",
        "# Exclude highly correlated variables like TotalDamage and focus on TotalDamageAdjusted\n",
        "target = LINEAR_TARGETS\n",
        "\n",
        "X = base_df[predictors]\n",
        "y = base_df[target]\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'pandas.core.strings' has no attribute 'StringMethods'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, label\u001b[38;5;241m=\u001b[39my_train) \n\u001b[0;32m      4\u001b[0m test_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_test, label\u001b[38;5;241m=\u001b[39my_test, reference\u001b[38;5;241m=\u001b[39mtrain_data)\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"LightGBM, Light Gradient Boosting Machine.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/microsoft/LightGBM/graphs/contributors.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     PANDAS_INSTALLED,\n\u001b[0;32m     24\u001b[0m     PYARROW_INSTALLED,\n\u001b[0;32m     25\u001b[0m     arrow_cffi,\n\u001b[0;32m     26\u001b[0m     arrow_is_boolean,\n\u001b[0;32m     27\u001b[0m     arrow_is_floating,\n\u001b[0;32m     28\u001b[0m     arrow_is_integer,\n\u001b[0;32m     29\u001b[0m     concat,\n\u001b[0;32m     30\u001b[0m     dt_DataTable,\n\u001b[0;32m     31\u001b[0m     pa_Array,\n\u001b[0;32m     32\u001b[0m     pa_chunked_array,\n\u001b[0;32m     33\u001b[0m     pa_ChunkedArray,\n\u001b[0;32m     34\u001b[0m     pa_compute,\n\u001b[0;32m     35\u001b[0m     pa_Table,\n\u001b[0;32m     36\u001b[0m     pd_CategoricalDtype,\n\u001b[0;32m     37\u001b[0m     pd_DataFrame,\n\u001b[0;32m     38\u001b[0m     pd_Series,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_lib_path\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\compat.py:152\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_delayed \u001b[38;5;28;01mas\u001b[39;00m dask_array_from_delayed\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_delayed \u001b[38;5;28;01mas\u001b[39;00m dask_bag_from_delayed\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame \u001b[38;5;28;01mas\u001b[39;00m dask_DataFrame\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series \u001b[38;5;28;01mas\u001b[39;00m dask_Series\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client, Future, default_client, wait\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, dispatch, rolling\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m         DataFrame,\n\u001b[0;32m      6\u001b[0m         Index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m         to_timedelta,\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Aggregation\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\backends.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msizeof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleSizeof, sizeof\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_arraylike, typename\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame, Index, Scalar, Series, _Frame\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     categorical_dtype_dispatch,\n\u001b[0;32m     26\u001b[0m     concat,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     union_categoricals_dispatch,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_array_nonempty, make_scalar\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:52\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m methods\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PANDAS_GT_140, PANDAS_GT_150\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatetimeAccessor, StringAccessor\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalAccessor, categorize\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     55\u001b[0m     get_parallel_type,\n\u001b[0;32m     56\u001b[0m     group_split_dispatch,\n\u001b[0;32m     57\u001b[0m     hash_object_dispatch,\n\u001b[0;32m     58\u001b[0m     meta_nonempty,\n\u001b[0;32m     59\u001b[0m )\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\accessor.py:112\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124;03m\"\"\"Accessor object for datetimelike properties of the Series values.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    >>> s.dt.microsecond  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStringAccessor\u001b[39;00m(Accessor):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;124;03m\"\"\"Accessor object for string properties of the Series values.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    >>> s.str.lower()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\accessor.py:124\u001b[0m, in \u001b[0;36mStringAccessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m _accessor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m _not_implemented \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_dummies\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;129m@derived_from\u001b[39m(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringMethods\u001b[49m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, pat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expand:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.core.strings' has no attribute 'StringMethods'"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from src.const import LINEAR_TARGETS, ATTRIBUTES\n",
        "\n",
        "predictors = ATTRIBUTES + CATEGORICAL_TARGETS \n",
        "mse_results = {}\n",
        "\n",
        "for target in (LINEAR_TARGETS + CATEGORICAL_TARGETS):\n",
        "    X = base_df[predictors]\n",
        "    y = base_df[target]  \n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PLONjkJT5u3",
        "outputId": "1a1b699d-b61b-4859-f5f6-c005fa70d892"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: MainLandfallLocation: object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m num_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 3\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(X_train, num_iteration\u001b[38;5;241m=\u001b[39mbst\u001b[38;5;241m.\u001b[39mbest_iteration)\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:3637\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   3631\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   3632\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3633\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   3634\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3635\u001b[0m     )\n\u001b[0;32m   3636\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 3637\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3638\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   3639\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2576\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2571\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2572\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2573\u001b[0m             )\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2575\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2576\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2582\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2106\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2104\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 2106\u001b[0m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:848\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    844\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    845\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdf_dtypes)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 848\u001b[0m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    849\u001b[0m     feature_name,\n\u001b[0;32m    850\u001b[0m     categorical_feature,\n\u001b[0;32m    851\u001b[0m     pandas_categorical,\n\u001b[0;32m    852\u001b[0m )\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:794\u001b[0m, in \u001b[0;36m_pandas_to_numpy\u001b[1;34m(data, target_dtype)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pandas_to_numpy\u001b[39m(\n\u001b[0;32m    791\u001b[0m     data: pd_DataFrame,\n\u001b[0;32m    792\u001b[0m     target_dtype: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.typing.DTypeLike\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 794\u001b[0m     \u001b[43m_check_for_bad_pandas_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:784\u001b[0m, in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[1;34m(pandas_dtypes_series)\u001b[0m\n\u001b[0;32m    778\u001b[0m bad_pandas_dtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m    782\u001b[0m ]\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[1;32m--> 784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    787\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: MainLandfallLocation: object"
          ]
        }
      ],
      "source": [
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    metric='mse',\n",
        "    boosting_type='gbdt',\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# Create an MSE scoring function for GridSearch\n",
        "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=lgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring=mse_scorer,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the final model using the best parameters\n",
        "best_model = lgb.LGBMRegressor(**best_params)\n",
        "\n",
        "# Fit the model on the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "3IDrRytOpuYf",
        "outputId": "36eaa272-7177-437f-a38e-c1206e284caa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"importance_df\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"DisasterSubtype_Severe weather\",\n          \"DisasterSubtype_Storm surge\",\n          \"Year\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Importance\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          72,\n          42,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "importance_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ee7f887a-f6ee-4c7e-b0d0-1036545a06f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Year</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LandfallPressure(mb)</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Month</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LandfallMagnitude(kph)</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Slide</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>DisasterSubtype_Tropical cyclone</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Flood</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DisasterSubtype_Hail</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DisasterSubtype_Lightning/Thunderstorms</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>DisasterSubtype_Severe weather</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee7f887a-f6ee-4c7e-b0d0-1036545a06f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee7f887a-f6ee-4c7e-b0d0-1036545a06f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee7f887a-f6ee-4c7e-b0d0-1036545a06f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d239d39-a6c5-4ef6-a184-1bbdff396b94\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d239d39-a6c5-4ef6-a184-1bbdff396b94')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d239d39-a6c5-4ef6-a184-1bbdff396b94 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                    Feature  Importance\n",
              "4                                      Year          72\n",
              "1                      LandfallPressure(mb)          42\n",
              "5                                     Month          42\n",
              "0                    LandfallMagnitude(kph)          36\n",
              "3                                     Slide          30\n",
              "12         DisasterSubtype_Tropical cyclone           7\n",
              "2                                     Flood           0\n",
              "6                      DisasterSubtype_Hail           0\n",
              "7   DisasterSubtype_Lightning/Thunderstorms           0\n",
              "8            DisasterSubtype_Severe weather           0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature importance\n",
        "feature_importance = bst.feature_importance()\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the top 10 features\n",
        "importance_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDICT CATEGORICAL_TARGET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12fu8SmxsJcg"
      },
      "outputs": [],
      "source": [
        "from src.const import ATTRIBUTES, CATEGORICAL_TARGETS \n",
        "\n",
        "predictors = ATTRIBUTES + CATEGORICAL_TARGETS \n",
        "mse_results = {}\n",
        "\n",
        "for target in (LINEAR_TARGETS + CATEGORICAL_TARGETS):\n",
        "    X = base_df[predictors]\n",
        "    y = base_df[target]  \n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    metric='mse',\n",
        "    boosting_type='gbdt',\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# Create an MSE scoring function for GridSearch\n",
        "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=lgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring=mse_scorer,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the final model using the best parameters\n",
        "best_model = lgb.LGBMRegressor(**best_params)\n",
        "\n",
        "# Fit the model on the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "feature_importance = bst.feature_importance()\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the top 10 features\n",
        "importance_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Set up parameter grid\n",
        "param_grid = {\n",
        "    'iterations': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'depth': [3, 5, 7],\n",
        "    'l2_leaf_reg': [1, 3, 5],\n",
        "    'border_count': [32, 64, 128],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bylevel': [0.7, 0.8, 1.0]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "cat_model = CatBoostRegressor(silent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDICT LINEAR_TARGET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
            "6561 fits failed out of a total of 6561.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6561 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"d:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"d:\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 5873, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
            "  File \"d:\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
            "    self._train(\n",
            "  File \"d:\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: catboost/private/libs/target/data_providers.cpp:639: Currently only multi-regression, multilabel and survival objectives work with multidimensional target\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "d:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "CatBoostError",
          "evalue": "catboost/private/libs/target/data_providers.cpp:639: Currently only multi-regression, multilabel and survival objectives work with multidimensional target",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mcat_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      7\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\catboost\\core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
            "File \u001b[1;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mCatBoostError\u001b[0m: catboost/private/libs/target/data_providers.cpp:639: Currently only multi-regression, multilabel and survival objectives work with multidimensional target"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=cat_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test)\n",
        "\n",
        "feature_importance = best_model.get_feature_importance()\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "mse_train, mse_test, grid_search.best_params_, importance_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PREDICT CATEGORICAL_TARGET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ngboost import NGBRegressor\n",
        "ngb_model = NGBRegressor()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of boosting iterations\n",
        "    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate for each boosting step\n",
        "    'minibatch_frac': [0.7, 0.8, 1.0],  # Fraction of data to use for each boosting step\n",
        "    'max_depth': [3, 5],  # Maximum depth of base learners (trees)\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],  # Fraction of features to be used in each boosting round\n",
        "    'natural_gradient': [True, False]  # Whether to use natural gradients (default is True)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(estimator=ngb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test)\n",
        "\n",
        "mse_train, mse_test, grid_search.best_params_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
