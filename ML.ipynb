{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EventName</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DisasterType</th>\n",
       "      <th>DisasterSubtype</th>\n",
       "      <th>MainLandfallLocation</th>\n",
       "      <th>Flood</th>\n",
       "      <th>Slide</th>\n",
       "      <th>OFDAResponse</th>\n",
       "      <th>Appeal</th>\n",
       "      <th>Declaration</th>\n",
       "      <th>LandfallMagnitude(kph)</th>\n",
       "      <th>LandfallPressure(mb)</th>\n",
       "      <th>TotalDeaths</th>\n",
       "      <th>NoInjured</th>\n",
       "      <th>TotalDamage(000US$)</th>\n",
       "      <th>TotalDamageAdjusted(000US$)</th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STORM_NAN_1953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953</td>\n",
       "      <td>9</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>989</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>19400</td>\n",
       "      <td>211880</td>\n",
       "      <td>9.156133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STORM_VIOLET_1964</td>\n",
       "      <td>Violet</td>\n",
       "      <td>1964</td>\n",
       "      <td>9</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>989</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>94354</td>\n",
       "      <td>10.598376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STORM_IRIS_1964</td>\n",
       "      <td>Iris</td>\n",
       "      <td>1964</td>\n",
       "      <td>11</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>960</td>\n",
       "      <td>5100</td>\n",
       "      <td>20</td>\n",
       "      <td>70000</td>\n",
       "      <td>660479</td>\n",
       "      <td>10.598376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STORM_JOAN_1964</td>\n",
       "      <td>Joan</td>\n",
       "      <td>1964</td>\n",
       "      <td>11</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>980</td>\n",
       "      <td>2500</td>\n",
       "      <td>20</td>\n",
       "      <td>15000</td>\n",
       "      <td>141531</td>\n",
       "      <td>10.598376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STORM_KATE_1964</td>\n",
       "      <td>Kate</td>\n",
       "      <td>1964</td>\n",
       "      <td>11</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3000</td>\n",
       "      <td>28306</td>\n",
       "      <td>10.598376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID EventName  Year  Month DisasterType   DisasterSubtype  \\\n",
       "0     STORM_NAN_1953       NaN  1953      9        Storm  Tropical cyclone   \n",
       "1  STORM_VIOLET_1964   Violet   1964      9        Storm  Tropical cyclone   \n",
       "2    STORM_IRIS_1964      Iris  1964     11        Storm  Tropical cyclone   \n",
       "3    STORM_JOAN_1964      Joan  1964     11        Storm  Tropical cyclone   \n",
       "4    STORM_KATE_1964      Kate  1964     11        Storm  Tropical cyclone   \n",
       "\n",
       "   MainLandfallLocation  Flood  Slide  OFDAResponse  Appeal  Declaration  \\\n",
       "0                     8      0      0             0       0            0   \n",
       "1                     4      1      1             0       0            0   \n",
       "2                     5      1      0             0       0            0   \n",
       "3                     5      1      0             0       0            0   \n",
       "4                     6      1      0             0       0            0   \n",
       "\n",
       "   LandfallMagnitude(kph)  LandfallPressure(mb)  TotalDeaths  NoInjured  \\\n",
       "0                      92                   989         1000         20   \n",
       "1                      92                   989           18         20   \n",
       "2                     150                   960         5100         20   \n",
       "3                     130                   980         2500         20   \n",
       "4                     130                   970            0         20   \n",
       "\n",
       "   TotalDamage(000US$)  TotalDamageAdjusted(000US$)        CPI  \n",
       "0                19400                       211880   9.156133  \n",
       "1                10000                        94354  10.598376  \n",
       "2                70000                       660479  10.598376  \n",
       "3                15000                       141531  10.598376  \n",
       "4                 3000                        28306  10.598376  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.const import DATA_HEAD\n",
    "\n",
    "data_filename = DATA_HEAD / \"STORM_preprocessed_medianfill_1.csv\"\n",
    "base_df = pd.read_csv(str(data_filename), index_col=0)\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# I. Plan\n",
    "\n",
    "1. **Featue importance**\n",
    "2. **Categorical classification**\n",
    "3. **damage prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Categorical classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| **Mô hình**               | **Ưu điểm**                            | **Nhược điểm**                          | **Khi nào dùng?**                       |\n",
    "|---------------------------|----------------------------------------|----------------------------------------|----------------------------------------|\n",
    "| Logistic Regression       | Đơn giản, dễ hiểu                      | Chỉ hiệu quả với dữ liệu tuyến tính    | Dữ liệu tuyến tính                     |\n",
    "| KNN                       | Dễ triển khai                          | Dự đoán chậm với dữ liệu lớn           | Dữ liệu nhỏ, không tuyến tính          |\n",
    "| Decision Tree             | Dễ trực quan hóa                       | Dễ bị overfitting                      | Phân loại nhanh                        |\n",
    "| Random Forest             | Giảm overfitting                       | Tốn tài nguyên hơn Decision Tree       | Dữ liệu phức tạp                       |\n",
    "| SVM                       | Hiệu quả với không gian chiều cao      | Khó mở rộng cho dữ liệu lớn            | Dữ liệu chiều cao                      |\n",
    "| Naive Bayes               | Nhanh, hiệu quả                        | Giả định độc lập không luôn đúng       | Phân loại văn bản                      |\n",
    "| Gradient Boosting         | Kết quả tốt                            | Tốn tài nguyên                         | Dữ liệu phức tạp, cần hiệu quả cao     |\n",
    "| Neural Network (MLP)      | Học được mẫu phức tạp                  | Cần nhiều tài nguyên                   | Khi có nhiều dữ liệu                   |\n",
    "\n",
    "**Model selection**\n",
    "1. `Logistic Regression`\n",
    "2. `KNN`\n",
    "3. `Random Forest`\n",
    "   - Random Forest works well with data that has both linear and non-linear features. \n",
    "   - It does not require normalization or transformation of the data (i.e., the data does not need to follow the same distribution). \n",
    "   - The model minimizes overfitting by aggregating from multiple decision trees.\n",
    "4. `SVM with rbf or Polynomial kernel`\n",
    "   - SVM with RBF or Polynomial kernel can turn non-linear data into linear in higher space. \n",
    "   - Suitable if data is moderate in size (SVM does not scale well for large data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 SLIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORICAL_TARGETS :['Flood', 'Slide']\n",
      "ATTRIBUTES :['Year', 'Month', 'MainLandfallLocation', 'OFDAResponse', 'Appeal', 'Declaration', 'LandfallMagnitude(kph)', 'LandfallPressure(mb)']\n",
      "Train size 165\n",
      "Test size: 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.const import CATEGORICAL_TARGETS, ATTRIBUTES\n",
    "\n",
    "evaluate_dict = dict()\n",
    "\n",
    "print(f\"CATEGORICAL_TARGETS :{CATEGORICAL_TARGETS}\")\n",
    "print(f\"ATTRIBUTES :{ATTRIBUTES}\")\n",
    "\n",
    "slide_df = base_df.copy()\n",
    "X = slide_df[ATTRIBUTES]\n",
    "y = slide_df[CATEGORICAL_TARGETS[0]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Train size {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'confusion_matrix': array([[ 0,  5],\n",
       "         [ 0, 14]]),\n",
       "  'accuracy': 0.74,\n",
       "  'precision': np.float64(0.74),\n",
       "  'recall': np.float64(1.0)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.utils import evaluate\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "slide_lr = LogisticRegression(max_iter=epochs)\n",
    "slide_lr.fit(X_train, y_train)\n",
    "\n",
    "eval_values = evaluate(slide_lr, X_test, y_test, threshold=0.2) # thresh = 0.3 to bias recall\n",
    "evaluate_dict[slide_lr.__class__.__name__] = eval_values\n",
    "\n",
    "evaluate_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Damage prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
